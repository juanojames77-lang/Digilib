[
  {
    "filename": "1765884258803-Figures.pdf",
    "originalName": "Figures.pdf",
    "text": "\n\nTimestamp\nName\nCourse\nYear\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I don\nt understand the topic. \nI apply what I\nve learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorial\ns content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\n0.00\n0.25\n0.50\n0.75\n1.00\n1.25\n1.50\n1.75\n2.00\nFigure 1: Missing Responses per Survey Item\n\nBSES\nBEED\nBSHM\nBSCS\nBSED-MATH\nBTLED-HE\nCourse\n0\n10\n20\n30\n40\n50\n60\nFigure 2: Distribution of Respondents by Course\n\n3rd Year\n4th Year\n2nd Year\n1st Year\nYear\n0\n20\n40\n60\n80\nFigure 3: Distribution of Respondents by Year Level\n\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I don\nt understand the topic. \nI apply what I\nve learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorial\ns content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\n0\n1\n2\n3\n4\nFigure 4: Mean Likert Scores of Student Engagement Items\n\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I don\nt understand the topic. \nI apply what I\nve learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorial\ns content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\n3.5\n4.0\nFigure 5: Median Likert Scores of Survey Items\n\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I don\nt understand the topic. \nI apply what I\nve learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorial\ns content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n1.2\nFigure 6: Variance of Responses per Survey Item\n\nWatching online tutorials is enjoyable for me. I feel motivated to watch online tutorials about topics that interest me. I find online tutorials interesting and engaging. I feel satisfied after watching a helpful tutorial. I enjoy learning new skills or concepts through online tutorials. I wish the tutorials I watch would last longer when they are informative. I watch online tutorials regularly. I focus my attention while watching online tutorials. I take notes while watching tutorials to remember key points.I try to finish the entire tutorial video instead of stopping midway. I replay parts of a tutorial when I dont understand the topic. I apply what Ive learned from tutorials to real activities or assignments. I look for more tutorials on similar topics after watching one.I put effort into understanding the content of the tutorials I watch. I think deeply about how the tutorials content relates to what I already know. I try to summarize or explain the tutorial content in my own words. I use critical thinking to evaluate the accuracy of the tutorial information. I connect what I learn from tutorials to real-life applications. I review or revisit tutorials to reinforce my understanding.I seek additional resources to supplement what I learn from tutorials.\n2.0\n2.5\n3.0\n3.5\n4.0\n4.5\n5.0\nFigure 7: Distribution of Student Engagement Responses\n\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I don\nt understand the topic. \nI apply what I\nve learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorial\ns content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I dont understand the topic. \nI apply what Ive learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorials content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\nFigure 8: Correlation Between Student Engagement Items\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n\n3.253.503.754.004.254.504.755.00\nOverall_Engagement\n0\n20\n40\n60\n80\nCount\nFigure 9: Overall Student Engagement Score Distribution\n\nHigh\n95.7%\nModerate\n4.3%\n0.0%\nFigure 10: Overall Student Engagement Levels\n\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I don\nt understand the topic. \nI apply what I\nve learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorial\ns content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\n0\n10\n20\n30\n40\n50\n60\n70\n80\nFigure 11: Strongly Agree Responses per Item\n\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I don\nt understand the topic. \nI apply what I\nve learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorial\ns content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\n0\n10\n20\n30\n40\n50\n60\nFigure 12: Disagree Responses per Item\n\nAgreeDisagreeStrongly agree\nWatching online tutorials is enjoyable for me. \n0\n20\n40\n60\n80\n100\n120\n140\ncount\nFigure 13: Response Distribution: Watching online tutorials is enjoyable f...\n\nStrongly agreeAgreeDisagree\nI feel motivated to watch online tutorials about topics that interest me. \n0\n20\n40\n60\n80\n100\n120\n140\n160\ncount\nFigure 14: Response Distribution: I feel motivated to watch online tutoria...\n\nAgreeStrongly agreeDisagree\nI find online tutorials interesting and engaging. \n0\n20\n40\n60\n80\n100\n120\n140\n160\ncount\nFigure 15: Response Distribution: I find online tutorials interesting and ...\n\nStrongly agreeAgree\nI feel satisfied after watching a helpful tutorial. \n0\n20\n40\n60\n80\n100\n120\n140\n160\ncount\nFigure 16: Response Distribution: I feel satisfied after watching a helpfu...\n\nAgreeStrongly agreeDisagree\nI enjoy learning new skills or concepts through online tutorials. \n0\n20\n40\n60\n80\n100\n120\n140\n160\ncount\nFigure 17: Response Distribution: I enjoy learning new skills or concepts ...\n\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I dont understand the topic. \nI apply what Ive learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorials content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\n1\n2\n3\n4\nFigure 18: Radar Chart of Mean Engagement Scores\n\nBEED\nBSCS\nBSED-MATH\nBSES\nBSHM\nBTLED-HE\nCourse\n0\n1\n2\n3\n4\nFigure 19: Mean Engagement Score by Course\n\n1st Year\n2nd Year\n3rd Year\n4th Year\nYear\n0\n1\n2\n3\n4\nFigure 20: Mean Engagement Score by Year Level"
  },
  {
    "filename": "1765884831978-Figures.pdf",
    "originalName": "Figures.pdf",
    "text": "\n\nTimestamp\nName\nCourse\nYear\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I don\nt understand the topic. \nI apply what I\nve learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorial\ns content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\n0.00\n0.25\n0.50\n0.75\n1.00\n1.25\n1.50\n1.75\n2.00\nFigure 1: Missing Responses per Survey Item\n\nBSES\nBEED\nBSHM\nBSCS\nBSED-MATH\nBTLED-HE\nCourse\n0\n10\n20\n30\n40\n50\n60\nFigure 2: Distribution of Respondents by Course\n\n3rd Year\n4th Year\n2nd Year\n1st Year\nYear\n0\n20\n40\n60\n80\nFigure 3: Distribution of Respondents by Year Level\n\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I don\nt understand the topic. \nI apply what I\nve learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorial\ns content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\n0\n1\n2\n3\n4\nFigure 4: Mean Likert Scores of Student Engagement Items\n\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I don\nt understand the topic. \nI apply what I\nve learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorial\ns content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\n3.5\n4.0\nFigure 5: Median Likert Scores of Survey Items\n\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I don\nt understand the topic. \nI apply what I\nve learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorial\ns content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n1.2\nFigure 6: Variance of Responses per Survey Item\n\nWatching online tutorials is enjoyable for me. I feel motivated to watch online tutorials about topics that interest me. I find online tutorials interesting and engaging. I feel satisfied after watching a helpful tutorial. I enjoy learning new skills or concepts through online tutorials. I wish the tutorials I watch would last longer when they are informative. I watch online tutorials regularly. I focus my attention while watching online tutorials. I take notes while watching tutorials to remember key points.I try to finish the entire tutorial video instead of stopping midway. I replay parts of a tutorial when I dont understand the topic. I apply what Ive learned from tutorials to real activities or assignments. I look for more tutorials on similar topics after watching one.I put effort into understanding the content of the tutorials I watch. I think deeply about how the tutorials content relates to what I already know. I try to summarize or explain the tutorial content in my own words. I use critical thinking to evaluate the accuracy of the tutorial information. I connect what I learn from tutorials to real-life applications. I review or revisit tutorials to reinforce my understanding.I seek additional resources to supplement what I learn from tutorials.\n2.0\n2.5\n3.0\n3.5\n4.0\n4.5\n5.0\nFigure 7: Distribution of Student Engagement Responses\n\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I don\nt understand the topic. \nI apply what I\nve learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorial\ns content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I dont understand the topic. \nI apply what Ive learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorials content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\nFigure 8: Correlation Between Student Engagement Items\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n\n3.253.503.754.004.254.504.755.00\nOverall_Engagement\n0\n20\n40\n60\n80\nCount\nFigure 9: Overall Student Engagement Score Distribution\n\nHigh\n95.7%\nModerate\n4.3%\n0.0%\nFigure 10: Overall Student Engagement Levels\n\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I don\nt understand the topic. \nI apply what I\nve learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorial\ns content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\n0\n10\n20\n30\n40\n50\n60\n70\n80\nFigure 11: Strongly Agree Responses per Item\n\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I don\nt understand the topic. \nI apply what I\nve learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorial\ns content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\n0\n10\n20\n30\n40\n50\n60\nFigure 12: Disagree Responses per Item\n\nAgreeDisagreeStrongly agree\nWatching online tutorials is enjoyable for me. \n0\n20\n40\n60\n80\n100\n120\n140\ncount\nFigure 13: Response Distribution: Watching online tutorials is enjoyable f...\n\nStrongly agreeAgreeDisagree\nI feel motivated to watch online tutorials about topics that interest me. \n0\n20\n40\n60\n80\n100\n120\n140\n160\ncount\nFigure 14: Response Distribution: I feel motivated to watch online tutoria...\n\nAgreeStrongly agreeDisagree\nI find online tutorials interesting and engaging. \n0\n20\n40\n60\n80\n100\n120\n140\n160\ncount\nFigure 15: Response Distribution: I find online tutorials interesting and ...\n\nStrongly agreeAgree\nI feel satisfied after watching a helpful tutorial. \n0\n20\n40\n60\n80\n100\n120\n140\n160\ncount\nFigure 16: Response Distribution: I feel satisfied after watching a helpfu...\n\nAgreeStrongly agreeDisagree\nI enjoy learning new skills or concepts through online tutorials. \n0\n20\n40\n60\n80\n100\n120\n140\n160\ncount\nFigure 17: Response Distribution: I enjoy learning new skills or concepts ...\n\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I dont understand the topic. \nI apply what Ive learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorials content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\n1\n2\n3\n4\nFigure 18: Radar Chart of Mean Engagement Scores\n\nBEED\nBSCS\nBSED-MATH\nBSES\nBSHM\nBTLED-HE\nCourse\n0\n1\n2\n3\n4\nFigure 19: Mean Engagement Score by Course\n\n1st Year\n2nd Year\n3rd Year\n4th Year\nYear\n0\n1\n2\n3\n4\nFigure 20: Mean Engagement Score by Year Level"
  },
  {
    "filename": "1765885129068-FyrVISION-REVISED-MANUSCRIPT (1).pdf",
    "originalName": "FyrVISION-REVISED-MANUSCRIPT (1).pdf",
    "text": "\n\nFYRVISION:INTEGRATINGDEEPLEARNINGFORFIREDETECTIONUSING\nYOLOv9\nEulysesT.Betasolo\nJohnDyVincentC.Osio\nMaryJhanelynR.Ceñal\nFebruary2025\n\ni\nFYRVISION:INTEGRATINGDEEPLEARNINGFORFIREDETECTIONUSING\nYOLOv9\n____________________\nAnUndergraduateThesis\nPresentedtotheFacultyofthe\nCollegeofScienceandManagement\nBOHOLISLANDSTATEUNIVERSITY\nClarinCampus,Clarin,Bohol\n____________________\nInPartialFulfillment\noftheRequirementsfortheDegree\ninBachelorofScienceinComputerScience\n____________________\nEulysesT.Betasolo\nJohnDyVincentC.Osio\nMaryJhanelynR.Ceñal\nFebruary2025\n\nii\nAPPROVALSHEET\nThisundergraduatethesisentitledFYRVISION:INTEGRATINGDEEP\nLEARNINGFORFIREDETECTIONUSINGYOLOv9,preparedandsubmitted\nbyEulysesT.Betasolo,JohnDyVincentC.Osio,andMaryJhanelynR.Ceñalin\npartialfulfillmentoftherequirementsforthedegreeBachelorofSciencein\nComputerSciencehasbeenexaminedandrecommendedforacceptanceand\napprovalfororaldefense.\nTHESISCOMMITTEE\nMARICHUC.LIBRES,PhD\nChairman\nARIELCHRISTIANC.VIODOR,DITMENCHIEA.LABRIGAS,MAEd-Eng\nThesisAdviserThesisEditor\nApprovedbytheExaminingPanelduringtheOral-Examinationconducted\nonFebruary05,2025witharatingof__.\n---------------------------------------------------------------------------------------------\nEXAMININGPANEL\nMARIETTAC.MACALOLOT,PhD\nChairman\nREYANTHONYG.GODMALIN,DITMARICHUC.LIBRES,PhD\nMemberMember\nALVINT.REMOLADO,MSc,LPTRAMILS.BULILAN,EdD\nMemberMember\nAcceptedandapprovedaspartialfulfillmentoftherequirementsforthedegree\nBachelorofScienceComputerScience.\nFebruary05,2025MARIETTAC.MACALOLOT,PhD\nDateofOralDefenseCampusDirector\n\niii\nACKNOWLEDGEMENT\nFirstandforemost,thethesiswriterssincerelythankAlmightyGodforHis\nblessings,guidance,strength,andinspiration,whichhavebeenthefoundationof\nthisstudy.WithoutHisdivinesupport,thisworkwouldnothavebeenpossible.\nWewouldalsoliketoexpressourheartfeltgratitudetothefollowingpeople,\nwhosecontributionswereessentialtothesuccessofthisresearch:\nDr.MariettaC.Macalolot,theCampusDirector,thankyouforallowingusto\npursuethisstudy.\nDr.MarichuC.Libres,theDeanoftheCollegeofScienceManagement,weare\ngratefulforyourmoralsupportandencouragement,whichmotivatedustofinish\nthiswork.\nDr.ArielChristianC.Viodor,theThesisAdviser,thankyouforyourguidance,\npatience,encouragement,andunwaveringsupportthroughoutthisjourney.Your\nknowledgeandadvicehavebeeninvaluableincompletingthisstudy.\nMs.MenchieA.Labrigas,MAEd-Eng,theThesisEditor,wedeeplyappreciate\nyourhardworkanddedicationinrefiningourmanuscript.\nProf.AlvinT.Remolado,LPT,MSc,thankyouforsharingtechniquesandinsights\nthathelpedusimprovethisresearch.\nDr.ReyAnthonyG.Godmalin,Prof.AlvinT.Remolado,Dr.MarichuC.Libres,Dr.\nRamilS.BulilanandDr.MariettaC.Macalolot,thepanelists,thankyouforyour\nconstructivefeedback,ideas,andguidance,whichgreatlycontributedtothe\nqualityofthisstudy.Dr.AlmeM.Aparicio,wealsothankyouforyoursupportand\nencouragementasourinstructor.\nFinally,weextendourdeepestgratitudetoourparents,relatives,andfriends.\nYourlove,encouragement,andunwaveringsupporthavebeenoursourceof\nstrengthandinspirationthroughoutthisjourney.Thisachievementisasmuch\nyoursasitisours.\n--ThesisWriters\n\niv\nABSTRACT\nFiredetectioniscriticalformaintainingsafetyinbuildingsandofficessinceearly\ndiscoverycanavoidpropertydamageandsavelives.Thisresearchfocuseson\ncreatingafiredetectionsystemutilizingtheYOLOv9-tmodel,whichisa\nlightweightandefficientdeep-learningarchitecture.Thesuggestedsystem\nanalyzesvideoframesinrealtimetoproperlydetectfire,resultinginauser-\nfriendly,modular,andefficientsolution.Thestudytacklesthedifficultyof\nestablishinghighaccuracyandreal-timeperformanceinfiredetectionsystems.\nManypresentsystemsstruggletostriketherightbalancebetweenprecisionand\nspeed,makingthemlesssuccessfulindynamiccontexts.Toaddressthis,the\nstudycomparestheYOLOv9-tmodeltotheSSD(SingleShotMultiBoxDetector)\ntoassessperformanceacrossseveraldetectionscenarios.Theprocessentails\ntrainingandtestingtheYOLOv9-tmodelonafiredetectiondatasettoensureit\ncandetectfiresinavarietyofcircumstances.Themodelscored88.5%mAP@50\nand72.3%mAP@50-95,indicatingoutstandingmulti-scaledetectioncapability.\nThecomparisonfoundthat,whileSSDslightlybeatYOLOv9-tinmAP@50,\nYOLOv9-ttriumphedinthemorecomprehensivemAP@50-95metric,\ndemonstratingadaptabilityandprecision.Finally,thestudydemonstratesthe\nefficacyofYOLOv9-tinfiredetection,providingadependableandscalable\nsolutionforreal-timemonitoring.Futureenhancementsshouldinvolvetrainingon\nlargerdatasetsandrefiningthemodelforincreasedperformance.Implementing\ntheseupgradeswillimprovethesystem'sefficiencyandefficacyinreal-world\nscenarios.\n\nv\nTABLEOFCONTENTS\nPage\nTITLEPAGE................................................................................i\nAPPROVALSHEET......................................................................ii\nACKNOWLEDGEMENT.................................................................iii\nABSTRACT................................................................................iv\nTABLEOFCONTENTS.................................................................v\nLISTOFFIGURES.......................................................................vii\nLISTOFTABLES.......................................................................viii\nChapter\n1THEPROBLEMANDITSSCOPE\nRationale..................................................................9\nLiteratureBackground................................................10\nTHEPROBLEM\nStatementoftheproblem............................................26\nSignificanceofthestudy.............................................27\nRESEARCHMETHODOLOGY\nDesign....................................................................29\nEnvironmentandParticipants......................................29\nInstrument...............................................................30\nPerformanceMetrics..................................................31\nDataset...................................................................33\nProcedure................................................................34\nGANTTCHART.................................................................39\n2PRESENTATION,ANALYSIS,ANDINTERPRETATIONOFDATA\nModelArchitecture....................................................40\nModelPerformance..................................................44\nDesignoftheSystemUI.............................................51\nSpecificationoftheProposedSystem...........................53\nModelComparison...................................................57\n\nvi\n3SUMMARY,CONCLUSIONS,ANDRECOMMENDATIONS\nSummary................................................................60\nFindings..................................................................60\nConclusions............................................................62\nRecommendations....................................................63\nDEFINITIONOFTERMS..............................................................64\nREFERENCES...........................................................................68\nAPPENDICES............................................................................72\nTHESISWRITERS’BIODATA........................................................75\n\nvii\nLISTOFFIGURES\nFigurePage\n1TheoreticalandConceptualFramework...........................................25\n2LocationMap..............................................................................30\n3ModelDevelopment.....................................................................34\n4SystemDevelopmentLifeCycle.....................................................35\n5ArchitectureoftheModel..............................................................41\n6TrainingTestandResults..............................................................45\n7TrainingandValidationLoss..........................................................46\n8ConfusionMatrix.........................................................................48\n9SystemArchitecture.....................................................................50\n10SystemDesign...........................................................................51\n11FunctionalRequirements..............................................................54\n\nviii\nLISTOFTABLES\nTablePage\n1ConfigurationoftheHyperparameters...............................................44\n2ModelEvaluation..........................................................................47\n3Non–FunctionalRequirements......................................................55\n4ModelComparison........................................................................58\n\nChapter1\nTHEPROBLEMANDITSSCOPE\nRationale\nFireoutbreaksposeaconstantthreat,threateninglivesandinflicting\nseverepropertydamage.Traditionalfiredetectionmethods,heavilyrelianton\nhumanobservationandrudimentarysensors,oftenresultinerrorandincreasing\nthepotentialforsignificantharm(Zangetal.,2023).However,advancementsin\ndeeplearninghaveinitiatedanideachange,offeringinnovativesolutionslike\ncomputervisionalgorithmscapableofachievinghighlyaccuratefiredetection\n(Avazovetal.,2023).Thisnewlydevelopedtechnologyhasthepotentialtoalter\nfirepreventionstrategiesentirely.\nTheproblemsofcurrentfiredetectionsystems,dependentonmanual\nobservationorrudimentarysensorsarepronetoerrorsandlags,which\ndramaticallyraisesthepossibilityofrisk,casualties,andpropertylossduringfire\nthreatsituations(Khanetal.,2022).Toimproveoverallfiresafety,reliableand\nefficientfiredetectionsystemsaredesperatelyneeded.Toaddressthiscritical\nchallenge,FyrVisionproposesaninnovativefiredetectionsystemthatintegrates\ndeeplearningalgorithms,specificallyutilizingtheYOLOv9architecture,withina\nCCTVdashboardpluginonacomputer.Thissystemenablesintelligentandreal-\ntimefiredetection.ByharnessingthepowerofConvolutionalNeuralNetworks\n(CNNs),knownfortheirexceptionalperformanceinimagerecognitiontasks,\nFyrVisionanalyzesvisualdatafromlivevideofeedstodetectpotentialfire\nthreatswithremarkableperformance.\n\n10\nThisinnovativemethodmadeuseofConvolutionalNeuralNetworks\n(CNNs),averyeffectivedeeplearningmodelknownforitsabilitytoperform\nimagedetectiontasks.CNNs’remarkableperformanceinimagerecognitionis\nexactlyalignedwiththerequirementsoftheproposedsystem,makingthemideal\nforanalyzingvisualdatarelatedtofiredetection.FyrVision'smaingoalwasto\nimprovefiresafetyprotocolsbyofferingreliableandproactivefiredetection\ncapabilities.FyrVisionsoughttoraiseoverallfiresafetystandardsandreducethe\ndangersrelatedtofireoutbreaksbyutilizinginnovativedeeplearningtechnology.\nByfocusingonearlyidentificationofpossiblefirerisks,thesystemguaranteed\nearlyreactionandfirehazardreduction,eventuallypreventingfatalitiesand\nminimizingpropertydamage.\nLiteratureBackground\nThissectiondiscussestherelatedworksinthefieldofvariousdetection\nforfirehazardsbasedontheirdifferenttechniquestodetect.Thestudyuseda\ndifferentwayofdetectingfirehazardstotheenvironment.Thisstudypresents\nfiredetectiontechniquestofindasolutiontotheproblemsoffirehazards,\nespeciallyfocusingontheclassificationofvarioustechniquessuchasthe\ndetectionoffireusingIoTtechnology,sensors,detectionthroughimage\nprocessing,andcamera-baseddetection.Theimportanceoffiredetectionisto\nsolvethecommonproblemsinourenvironment.\nThefollowingliteraturespresentedaresupportedbythedifferentlaws\nrelatingtothestudysuchas:\n\n11\nSection(1).“AnActAdoptingInnovationasVitalComponentoftheCountry’s\nDevelopmentPoliciestoDriveInclusiveDevelopment,PromotetheGrowthand\nNationalCompetitivenessofMicro,SmallandMediumEnterprises,\nAppropriatingFundsTherefor,andforOtherPurposes”\nTheREPUBLICACTNO.9514“AnActEstablishingaComprehensiveFireCode\nOfThePhilippines,RepealingPresidentialDecreeNo.1185AndForOtherPurposes”\nSection1statesthat:\nSection(1).“ThisActshallbeknownasthe“FireCodeofthePhilippinesof2008”.\nSection2statesthat:\nThislawaimstomakesurepeoplearesafefromfires,helpbusinesses\ngrowbypreventingfires,andmakefirefightingarespectedprofession.Todothis,\nthegovernmentwillenforcerulestopreventfiresandmakesurefirefightersare\ndoingtheirjobproperly.Thethesiswritersalsocameupwithanideatobuildand\nintegratingdeeplearningforfiredetectionwithemergencyalarmsystemtohelp\nthecommunityandhavesafetyalert.\nTheRepublicActNo.11293alsoknownas“PHILIPPINEINNOVATION\nACT”,statesthat:\nTheActaimstoremovetheobstaclestoinnovationbysuppressing\nbureaucratichurdlesandencouragingentrepreneurialattitudetostimulate\ngrowthambitionsinbusiness,especiallythemicro,small,andmedium\nSection(2).“ItisthepolicyoftheStatetoensurepublicsafety,promoteeconomic\ndevelopmentthroughthepreventionandsuppressionofallkinds,ofdestructive\nfires,andpromotetheprofessionalizationofthefireserviceasaprofession.\nTowardsthisend,theStateshallenforcealllaws,rules,andregulationstoensure\nadherencetostandardfirepreventionandsafetymeasures,andpromote\naccountabilityinthefireprotectionandpreventionservice.”\n\n12\nenterprises(MSMEs).TheActcreatedtheNationalInnovationCouncil(NIC)\ntaskedtodevelopthecountry’sinnovationgoals,priorities,andlong-term\nnationalstrategy.\nTheRepublicActNo.11589“AnActStrengtheningAndModernizingThe\nBureauOfFireProtectionAndAppropriatingFundsTherefor”\nSection1statesthat:\nSection2statesthat:\nTheActdeclaresthepolicyoftheStatetoensurepublicsafetyby\npreventingandsuppressingdestructivefireswiththeactiveinvolvementofthe\ncommunity.TheActemphasizestheformulationandimplementationofplansand\nprogramstoenhanceandmodernizetheBFP,expanditsmandateandcapability,\nandensureitsresponsivenesstotheevolvingneedsofthecommunity.\nSection(1).“ThisActshallbeknownasthe“BureauofFireProtection\nModernizationAct.”\nSection(2).“DeclarationofPolicy.–ItisthepolicyoftheStatetoensurepublic\nsafetythroughthepreventionandsuppressionofallkindsofdestructivefires,with\ntheactivesupportofthecommunity.Towardsthisend,theStateshallformulate\nandimplementplansandprogramstoenhanceandmodernizetheBureauofFire\nProtection,expanditsmandateandcapability,andensureitsresponsivenessto\nthechangingneedsofthecommunity.”\n\n13\nByutilizingtheIPOmodel,thisstudyaimstounderstandhowinputdata\n(suchasvisualimageryforfiredetection)isprocessedusingdeeplearning\nalgorithmstogenerateaccuratepredictions(output)thattriggersemergency\nalarmsystem.AccordingtoPNA(PhilippineNewsAgency),“Manila–The\ncountryhasseena25percentincreaseinthenumberoffireincidentsinthefirst\ntwomonthsoftheyear,mostofwhichoccurredinresidentialareas.Speakingat\naBagongPilipinasNgayonbriefingonFriday,BureauofFireProtection(BFP)\nspokespersonFireSupt.AnnaleeCarbajal-Atienzasaidatotalof3,044fire\nincidentswerereportedfromJanuary1toMarch1,2024thisyear,from2,424\nincidentsloggedinthesameperiodlastyear.Smokingistheleadingcauseof\nfireincidents,followedbyunattendedopenflamesfromcookingandelectric\nignitions,sheadded”.AccordingtothestudyofBuandGharajeh(2019),entitled\n“Intelligentandvision-basedfiredetectionsystems:Asurvey.Imageandvision\ncomputing”.Thesaidpaperdiscussesthevariousenvironmentalproblemsoffire\ninbuildings,forests,andminesusinganintelligentsystemthatdetectsfirewith\nvision-basedtechnology.Thegoalistogivefirefightersandfiredepartmentsthe\nessentialassistancetheyneedtolocateandidentifyfiresinsomeareas.The\nsaidstudyisveryrelatedtotheproposedsystemasitdealswithfiredetectionin\nareal-timevision.\nThestudyofSarvariandMazinani(2019),entitled“anewtunnelfire\ndetectionandsuppressionsystembasedoncameraimageprocessingandwater\nmistjetfans”.Inthestudy,anewtunnelfiredetectionandextinguishingsystem\nwasdeveloped.Ratherthanemployingtraditionalmethods,suchasjustspraying\n\n14\nwater,thissystemmakesuseofcamerastodetectafireinsideatunneland\npowerfulfanstoshutdownafire.Thefanscreatemoisturethatentersthetunnel,\nfacilitatingtheentryoffreshairandhelpinginthecontrolofthefire.Moreover,\ntestsshowedthatthissystemimprovesthepreviousone.Itdecreasedthe\namountofheatreleasedandcontrolledfiresmorequickly.Additionally,it\nincreasedtunnelvisibility,whichisimportanttosafety.Thetestsalsoprovedthat\nthenewsystemmetallthesafetystandardsneededfortunnelfires.Thismeans\nitcanstopfiresfromspreading,letfirefightersgetintoputthemout,andkeep\nthetunnelfromgettingdamaged.Overall,thestudyshowsthatthisnewsystem\niseffectiveandmeetsalltheimportantsafetyrules.Thesaidstudyhas\nsimilaritieswiththeproposedsystemasitbothdealswithfiredetectionacamera\nimageprocessing.\nInthestudyofHsuetal.(2019),entitled“ApplicationofInternetofThings\ninakitchenfirepreventionsystem”.Asystemtostopkitchenfiresfromspreading\noutofcontrolwasdevelopedbythisstudy.Itsoundsanalarm,alertsthe\nresidents,andturnsoffthegassupplyifitdetectsflames,gasleaks,orhigh\ntemperaturesinthekitchen.Italsoopensthemaindoortoallowfirefightersto\nenterquicklyandsendssignalstotheemergencyservicesandcommunity\nmanagement.Reducingtheannualnumberofcasualtiesandfatalitiesfrom\nkitchenfiresistheaimofthisapproach.\nAdditionally,italsoenablesuserstousetheirphonestomonitortheirgas\nburnerfromadistance.Ifneeded,theycanremotelyswitchitoff.Inthefuture,\n\n15\nscientistsmightinvestigateincludingprotectionsagainsttheriskofcarbon\nmonoxidepoisoning,soenhancinghousesafetyforresidents.Inthestudyof\nGeorgiadesetal.(2019),entitled“Integratedforestmonitoringsystemforearly\nfiredetectionandassessment”.Anewtechniqueforearlyforestfiredetectionis\npresentedinthisresearch.Itkeepsmonitoringforpossiblesignsoffireina\ndesignatedareaoftheforestusingpermanentcameras.Itautomaticallyrecords\nandmonitorsreal-timeenvironmentaldata,includingtemperature,winddirection,\nandspeed.\nFurthermore,anautomatedanalysisofallthedataisperformedto\ndeterminethepossibilityofafirehappening.Thetechnologyalertsusersvia\nemailsorSMSwhentherisklevelistoohigh.Adroneequippedwithcameras\ncanbesenttotakeacloserlooktoensuretheaccuracyoftheriskassessment.\nEveryoneinvolvediskeptinformedateverystepoftheprocess,andbefore\ntakingamajoraction,theirpermissionissecured.Organizationscanalsobenefit\ngreatlyfromthisapproach,whichhelpsthemmakedecisionsbasedondata.It’s\ninterestinginthatitcombinesmobileandstationarysensorstoprovidegood\nimagesatalowercost.Witheverythinginstalled,thissystemispreparedtobe\ntestedinactualforestplaces.Tofindouthowwellitperformsinactualforest\nsurroundings,testswillbeconductedinCyprus’PanoPlatresforestareas.\nApparently,thesaidstudyhassimilaritieswiththeproposedsystemasitdeals\nwithafiredetectionmonitoringsystem.\n\n16\nThestudyofKimandLee(2019),entitled“Avideo-basedfiredetection\nusingdeeplearningmodels”.Inspiredbythewaypeopleseetheworld,and\ndevelopedanewmethodoffiredetectioncalledDTA.Thestudybelievesittobe\nmoreaccurateinidentifyingflames.First,basedontheshapes,thestudy\nidentifiespossiblefirespotsusingaspecializedfiredetectionmodelknownas\nFasterR-CNN.Then,usinganalgorithmknownasLSTM,analyzessuchareas\nalongwithareasthatarefreeofflamesinasequenceofimagesorframes.This\naidsthemindeterminingwhetherthereisafirerightnow.Inaddition,majority\nvotingisusedtocombineallofthesetemporaryvotesintoafinaldecision\nregardingwhethertocontinuethefireforalongerperiod.Tounderstandhowthe\nfirebehaves,thestudyalsomonitorhowtheflameandfire’ssizechange\nthroughouttime.\nFurthermore,thestudytestshowedhowaccuratethesystemisin\nidentifyingflames.Itcanevenrecognizehowsmokeandflameschangeover\ntime,whichcouldhelppreventtheunnecessarydeploymentoffiremen.Totest\ntheapproach,italsogatheredanextensiveamountofimagesandvideosof\nflames.Othersmightusethisresourceinthefuturetoresearchfiredetection.\nApparently,thesaidstudyisveryrelatedtotheproposedsystemasitdealswith\nfiredetectionusingdeeplearningmodels.InthestudyofMoumgiakmasetal.\n(2021),entitled“ComputervisionforfiredetectiononUAVs–Fromsoftwareto\nhardware”.Inthelast10years,72academicpapersabouttheuseofdroneswith\ncomputervisiontodetectfireshavebeenstudiedforthisstudy.Between2016\n\n17\nand2019,thenumberofthesestudiesincreasedsignificantly;but,afterthe\nCOVID-19pandemichappened,therateofdevelopmentdecreased.\nMoreover,thereviewstudieddifferentdronemodels,sensors,hardware,\nandcomputervisionmodelsusedforfiredetection.Thestudyanalyzedthemany\ndrones,models,andtechniquestodeterminethebestwaytodetectfiresafter\nreviewingallthepapers.Itwasdiscoveredthathelicoptersareidealforthistask\nbecausetheycanstayandviewallaround.It’seasiertoidentifyfiresorsmoke\nearlywhenheatandvisiblelightsensorsareusedtogether.Thedrones’GPS\nandIMUsprovidelocationinformation.Whenappliedtothedroneitself,ERNet\ncomputervisiontechniquesarebetterandneedlesspower.However,VGG-16\nperformswellwhencomputationsareperformedlocally,althoughtakingalarge\namountofprocessingpower.CNNmodelsperformthebestoverall.ROSis\nusefulforrouteplanningandautonomousflying,whilePix4Disusefulformap\ncreation.Thesesoftwareapplicationsprovideawealthofhelpfulinformationand\nautomatemajorpartsofeverymission.Inaddition,thesaidstudyhassimilarities\nwiththeproposedsystemasitdealsalsowithfiredetectionareal-timevision.\nInthestudyofAlqourabahetal.(2021),entitled“Asmartfiredetection\nsystemusingIoTtechnologywithautomaticwatersprinkler”.Inthisstudythe\nmaingoalwastoputoutflames,earlierfiredetectionsystemswereslowtoreact.\nTherefore,usingIoTtechnologyalongwithtemperature,smoke,andgassensors,\nthisstudydevelopedanimprovedsystem.Thesesensorsgatherinformation\nquicklyandaccurately,andthensecurelytransferittoacentrallocationfor\nexamination.Watersprinklersareactivatedimmediatelyupondetectionofafire.\n\n18\nMoreover,theUbidotsplatformenabledfasterandmoreaccuratedataexchange.\nThenewsystemtakesanaverageof5secondstoidentifyafireandnotifythe\nowneroftheproperty.Atthesametime,thewaterpumpbeginsoperatingto\nreleasethefireuntilhelpshowsup.Thistechnologyisaccurateandimmediately\ncollectsandanalyzesdatatoenhancefiredetection.Still,there’sachanceof\ndevelopment.Insteadofonlydetectingfires,oneapproachistoapplymachine\nlearningtopredictfiresbeforetheyoccur.\nThestudyofKhanetal.(2023),entitled“AutomaticFireDetection,\nIndicationAndControllingSystemForCommercialBuildingUsingProgrammable\nLogicController”.Afirealarmsystemiswhatbeingsuggested.Thesensor\nsoundsanalarmthroughoutthebuildingandopensthewaterpumpvalveforthe\naffectedareawhenitsensesafire.Thiswarnsotherstoleave.Toavoidincidents,\ntheescapedoorsopenautomatically,andtheelevatorsdroptothegroundfloor.\nBytemporarilyputtingoutthefireuntilhelparrives,thismethodhelpssavelives.\nItcanbefoundinareaslikeschools,hospitals,offices,andmalls.Largeflames,\nhowever,maypreventindividualsfromalertingthefiredepartment,resultingin\nbiggerlosses.ThenextversionmighthaveanautomaticalertingGSMmoduleto\nhandlethis.Wi-Fimodulesmayalsoenablemobileapp-basedremotecontrol,\nwhichwouldbeusefulinlocationssuchasstorageareas.Inthismanner,users\ncanusetheirphonestoturnonthewaterpumpandalarmevenwhenthey’renot\nthere.Inaddition,thesaidstudyisveryrelatedtotheproposedsystemasit\ndealswithfiredetectionandawaterresponsesystem.\n\n19\nInthestudyofRehmanetal.(2021),entitled“Smartfiredetectionand\ndeterrentsystemforahumansaviorbyusinginternetofthings(IoT)”.Inthis\nwork,theSmartFireDetectionandDeterrentSystem(SMDD)isaproposed\napproach.Unlikesystemswithasinglesensor,themainpurposeistolocatefires\neffectivelywithoutsoundingfalsealarms.Severalsensorsareusedbyour\nsystemtomeasureheat,humidity,temperature,andsmoke.Thesesensors’data\nisexaminedusingfuzzylogic,anAI-basedmethod.Thisanalysisenablesthe\nsystemtodetectsmokelevelsintheairand,basedonhowdangerousthefireis,\nshownotificationsandtakeappropriateaction.\nInaddition,thedevicereleasesawatersprayasafirstlineofdefense\nwhenitdetectsafire,preventingbreathingdifficultiesuntilfiremenarrive.The\nstudypresentsadetaileddiscussionoftheoutcomesofsimulationsperformed\nwithMATLAB.Apparently,thesaidstudyhassimilaritieswiththeproposed\nsystemasitaimsfiredetection.InthestudyofTejaetal.(2022),entitled“IoT\nbasedfiredetectionandautomaticwatersprinklersystem”.Inearlierresearch,\nfiredetectionsystemsweredesignedtoputoutfires,buttheywereslowtoreact.\nInordertoimprovethefiredetectionsystem,thisresearchexaminedthose\nissues.Toquicklyandaccuratelygatherdata,itmakesuseofIoTtechnology\nalongwithsensorsfortemperature,gas,andsmoke.Thismethodimprovesthe\neffectivenessoffiredetection.Moreover,upondetectingafire,thewaterpump\nbeginsoperation,collectingwaterfromatankandsprayingittoputoutthe\nflamesuntilassistancecomes.Thecost,effectiveness,andresponsiveness\nissuesthatpriorsystemsfacedareresolvedbythisone.Apparently,thesaid\n\n20\nstudyisveryrelatedtotheproposedsystemasitdealswithfiredetectionanda\nwaterresponsesystem.\nInthestudyofJayashreeandJaneera(2016),entitled“Real-timefire\ndetection,alerting,andsuppressionsystemusinglivevideosurveillance”.This\nprojectsuggestsafiredetectionsystemusingdifferenttechniquestofindedges\nbasedoncolor,shape,andhowflamesmove.Thesystemtestedthisapproach\nusingvariousdatabasesmadefrombothliveandrecordedvideos.Thesizeof\nframesforeachedgedetectiontechniquerangesfromabout372by208pixelsto\n640by480pixels.Livevideoshaveaframerateofaround15to20framesper\nsecond,whilerecordedvideoshaveaframerateofabout15to30framesper\nsecond.\nThefiresuppressionsystemhasbeensuccessfullycombinedwiththefire\ndetectionsystemusingaUSBtoSERIALbus.Thismeansthatthissystemin\nreal-timedetects,suppresses,andalertsaboutfires.Thebiggestadvantageof\nthissystemisthatitactivatesthenearestsprinklerinsteadofallofthem,\nprotectingpropertiesthatarefarfromthefire.Thethesiswritersplantoconnect\naRaspberryPitorecordhigh-resolutionvideos(1080pixels)andhandlethem\nusingtheRaspberryPisingle-boardcomputerconnectedtoawebcam.\nInthestudyofOkoroIsrealandOmokaro(2017),entitled“Amodelof\nautomaticfiredetectionandsuppressionsystemwithimprovedefficiency”.This\nprojectcreatedandtestedanewsystemtomakefiremanagementmoreefficient\nandresponsive.Itusessignalfilters,energyreleasealgorithms,anda\nmicrocontrollerwithPIDcontroltospeedupthesystem'sresponsetimetofires\n\n21\nwhileminimizingerrors.Thegoalistoquicklydetectfireswithoutovershootingor\ncausingunnecessarydamage.Thesystemcanalsologtemperaturedatainreal\ntimeandcontroltemperaturebasedontheinformationitgathers.Thissimulation\nmodelhelpsreduceproblemslikefalsealarmsandwaterdamagecausedby\nuncontrolledsprinklers,whicharecommonintraditionalfiremanagement\nsystems.InthestudyofAlkhatib(2014),entitled“Areviewonforestfiredetection\ntechniques”.Forestfiresnotonlycausetragiclossoflivesandvaluable\npropertiesbutalsoposeasignificantthreattotheenvironmentbydamaging\nlargeareasofforestsandwildlifehabitats.Everyyear,forestfiresaroundthe\nworldleadtounimaginabledisasters.Manyresearchershavebeenstudyingthis\nproblemforyears,andtherearenumeroussolutionsavailablefortestingor\nimmediateuse.\nThisstudyaimstoreviewandsummarizeallthetechnologiesusedfor\nforestfiredetection,includingadetailedexaminationofthetechniquesand\nmethodsemployedintheseapplications.Thepaperwasdiscussedvarious\nmethodsandsystemsavailableinthemarketandforresearchpurposes,\nprovidingexamplesofexperimentalresultsandcommercialproductstohelp\nreadersunderstandbetter.Eachdetectiontechniquehasitsownstrengthsand\nweaknesses,whicharethoroughlydiscussedinthepaper.InthestudyofGoyal\netal.(2020),entitled“Ayolobasedtechniqueforearlyforestfiredetection”.In\nthisresearch,anautomaticearlywarningsystemwasdevelopedusingmultiple\nsensorsandadvanceddeeplearningalgorithms.Thegoalwastoachievehigh\naccuracyinreal-timefiredetectionataminimalcost.Droneswereequippedwith\n\n22\nsensors,RaspberryPi3,neuralsticks,APM2.5,GPS,andWi-Fi.Theneural\nstickprocessedimagesinreal-timeusingadeeplearningmodel.Whenafire\nwasdetected,theUAVsentanalerttoauthoritiesviaamobileapp,providing\ninformationonthefire'slocation,images,andaffectedareasize.\nThisimmediatenotificationenabledauthoritiestotakeswiftactionto\npreventthefirefromspreadingandcausingharmtolivesandproperty.By\ncombiningdeeplearningandinfraredcameras,theresearchcapitalizedon\nadvancedsurveillancetechnologiestodetectfireswithinthecriticalfirst12hours,\nwhentheyaremostmanageable.Inthisresearchwork,YOLObasedforestfire\ndetectionsystemisworkingwithanaccuracyof90%.Thesensitivityand\nspecificityforthepresentresearchare92%and90%respectively.Inthestudyof\nTalaat&ZainEldin(2023),entitled“Animprovedfiredetectionapproachbased\nonYOLO-v8forsmartcities”.Thispaperintroducesabetterapproachcalledthe\nSmartFireDetectionSystem(SFDS),usingtheYOLOv8algorithm,whichuses\ndeeplearningtospotfire-specificfeaturesquickly.\nTheSFDSaimstoimprovefiredetectionaccuracy,reducefalsealarms,\nandbecost-effectivecomparedtotraditionalmethods.Itcanalsodetectother\nhazardslikegasleaksorflooding.Thesystemisdesignedwithfourlayers:\nApplication,Fog,Cloud,andIoT.ByusingFogandCloudcomputingalongwith\nIoT,itcancollectandprocessdatainreal-time,leadingtofasterresponsesand\nlessdamagetopropertyandlives.TheSFDSperformsexcellently,achievinga\nprecisionrateof97.1%forallclasses,makingithighlyeffective.Ithasmany\npotentialuses,includingfiresafetyinpublicareas,forestfiremonitoring,and\n\n23\nsmartsecuritysystems.InthestudyofBahharetal.(2023),entitled“Wildfireand\nsmokedetectionusingstagedYOLOmodelandensembleCNN”.Thisresearch\ncontributestoourunderstandingbyassessingtheeffectivenessofawildfireand\nsmokedetectionsolutionusingacombinationofconvolutionalneuralnetwork\n(CNN)architectures.TheproposedmethodcombinestheYOLOarchitecturewith\ntwoweightswithavotingensembleCNNarchitecture,workingintwostagesto\nclassifyanddetectsmokeorfire.\nTheclassificationmodelachievedhighscoresduringtrainingandtesting,\nwitha0.95F1-score,0.99accuracy,and0.98sensitivity.Thedetectormodel\nalsoperformedwell,achievingameanaverageprecision(mAP)scoreof0.85for\nsmokedetectionand0.76forthecombinedmodel.Thesmokedetectionmodel\nachieveda0.93F1-score.Despitesomechallengesduringtraining,suchasthe\nlackofhigh-qualityreal-worldimages,thedeeplearningpipelinedemonstrated\npromisingexperimentalresultsandpotentialforimplementationinwildfire\ndetectionsystems.InthestudyofAvazovetal.(2021),entitled“Firedetection\nmethodinsmartcityenvironmentsusingadeep-learning-basedapproach”.This\nstudyintroducesafiredetectorcapableofquicklyandaccuratelydetectingeven\nsmallsparks,triggeringanalarmwithin8secondsofafireoutbreak.Anovel\nconvolutionalneuralnetwork(CNN)wasdevelopedbasedontheenhancedYou\nOnlyLookOnce(YOLO)v4algorithm.Thisnetworkwasoptimizedtorun\nefficientlyontheBananaPiM3boardusingonlythreelayers.Initially,\nexperimentswiththeoriginalYOLOv4approachdidnotyieldtheexpected\nresultsforfiredetection.However,byaugmentingthetrainingdatasetand\n\n24\nmodifyingthenetworkstructure,theproposedmethodsuccessfullydetectedand\nalertedtheoccurrenceoffireswithhighspeedandaccuracyinvariousweather\nconditions.\nExperimentalresultsdemonstratetheeffectivenessoftheproposed\nmethodforsafeguardingsmartcitiesandmonitoringurbanfires.Comparisons\nwithotherfiredetectionapproachesusingstandardperformancemetricsfurther\nvalidatetheperformanceoftheproposedmethod.Theaccuracyofthesystem\nYOLOv4rankedthehighestintrainingwith98.8%accuracy.Furthermore,\nYOLOv3achieved97.1%(adifferenceof1.7%fromYOLOv4)andmarginally\ntrailedYOLOv4intermsofthetestingaccuracy.Thiswasfollowedby\nYOLOv4tinyandYOLOv4tiny_3l.Thesealgorithmsconsumedmoretimethan\nthoseinpreviousexperimentsbecauseoftheincreasednumberofdataset\nimages.YOLOv4wasconsideredasanefficientandpowerfulfiredetection\nmodelwiththehighestpredictionaccuracy,evenwhentheprocessingtimewas\nlessthanthatoftheYOLOv4_tinyalgorithm.\nInsummary,FyrVision'sinnovativesolutiontofiredetectionintegrates\ndeeplearningalgorithms,specificallyutilizingtheYOLOv9architecture,intoa\nCCTVdashboardpluginonacomputer.FyrVisionusesConvolutionalNeural\nNetworks(CNNs)toanalyzevisualdatafromlivevideofeedsinrealtime,\nallowingforhighlyaccurateintelligentfiredetection.Thisproactivesolutionnot\nonlyincreasesoverallfiresafetystandardsbutalsoreducestherisksconnected\nwithfireoutbreaks.FyrVision'stechnologyenablestimelyresponsesbydetecting\nfirerisksearlyon,thussavinglivesandreducingpropertydamage.\n\n25\nConceptualTheoryLegalBases\nIPOmodel\nTheRepublicActNo.9514,also\nknownastheRevisedFireCodeof\nthePhilippinesof2008\nTheRepublicActNo.11859\nKnownasthe“BureauofFire\nProtectionModernizationAct\nInputs\nInformationonexistingfiredetectionandsuppressionsystems.\nCameraframes\nFireDataParameters\n\n26\nTHEPROBLEM\nStatementoftheProblem\nThegoalofthisresearchwastoIntegrateDeepLearningforFire\nDetectionusingYOLOv9.\nSpecifically,itaimedtoanswerthefollowingquestions:\n1.Whatisthemodel’sarchitecture?\n2.Whatistheperformanceofthemodelintermsofthefollowingmetrics;\n2.1.mAP50,and\n2.2.mAP50-95?\nProcess\nModelDevelopment\nSystemDevelopmentLifeCycle(SDLC)\nYolov9\nOutput\nModel\nFYRVISION:IntegratingDeeplearningForFireDetectionusing\nYOLOv9\n\n27\n3.Whatisthedesignofthesystemintermsof:\n3.1SystemArchitecture;and\n3.2SystemDesign?\n4.Whatistherequirementsspecificationoftheproposedsystemintermsof;\n4.1FunctionalRequirements;and,\n4.2Non-functionalRequirements?\n5.Whatisthecomparisonwithothermodelsintermsofperformance?\n5.1SSD\nSignificanceoftheStudy\nThestudyofintegratingdeeplearningforfiredetectionwithan\nemergencyalarmsystemhassignificanteffectsonvariouskindsofstakeholders,\nincludingpropertyowners,firefighters,andthesiswriter’s.Thisstudyaimedto\nenhancefiresafetyalarm,minimizefalsealarms,andimproveemergencyalarm\ncapabilitiesbyutilizingcamerasandalarmsystems.\nPropertyowners.Integratingdeeplearningalgorithmspromises\nimprovedfirepreventionmeasures,loweringthedangerofpropertydamageand\nincreasingassetprotection.Timelyfiredetectionandautomatedsoundalert\ndevicescangreatlyreducepotentiallossesandcontributetoasaferlivingand\n\n28\nworkingenvironment.\nFirefightersandemergencyresponders.Itwouldbenefitfromincreased\noperatingefficiencyandeffectiveness.Advancedfiredetectionsystemsthatuse\ndeeplearningalgorithmsgiveessentialinformationfortimelyandtargeted\nreactionmeasures.Thisresultsinlowerrisksforrespondersandbetter\noutcomesduringfirefightingoperations.\nThesisWriters.Thisstudywouldprovideanopportunityforthesis\nwriterstohelpenhancefiresafetytechnology.Exploringtheintegrationofdeep\nlearningwithanemergencyalarmsystemscanresultincreativeideasand\ninsightsthatcanbeimplementedinreal-worldcircumstances.\nFutureThesisWriters.Thefindingsofthisstudywouldserveasa\nfoundationforfutureresearchinthefieldsoffiredetectionandemergencyalarm\nsystems.\nComputerScienceField.Thisstudywouldoffervaluableinsightsintothe\nintegrationofYOLOforfiredetectionandrepresentsanadvancementin\nintelligentforemergencyalarmsystems,providingopportunitiesforfurther\nresearchanddevelopmentinthefieldofcomputervisionandartificialintelligence.\n\n29\nRESEARCHMETHODOLOGY\nDesign\nInthisstudy,atrue-experimentalresearchdesignwasemployedto\nevaluatetheperformanceandeffectivenessoftheproposedsystem,\"FyrVision:\nIntegratingDeepLearningforFireDetectionUsingYOLOv9,\"whichdetectsfire\nfromaCCTVdashboardonacomputer.Thisdesignisthemosteffectivein\ngeneratingcause-and-effectrelationshipsandenablescomparisonsand\nevaluationsofthemodel'sfunctionalityincontrolledenvironments(Campbell&\nStanley,1966).TodetectfireundercontrolledconditionsusingYOLOv9within\ntheFyrVisionsystem,theprocessentailspreparingavariedfiredataset,\nannotatingfirescenarios,trainingthemodel,validatingitsperformance,\ndeployingittotheCCTVdashboard,andcontinuouslymonitoringandoptimizing\n\n30\nitsperformance.Thestudyintendedtoestablishaclearcause-and-effect\nrelationshipbetweenthefiredetectionsystemanditsabilitytoreducefire\ndamageandenhanceoverallfiresafetybycomparingthesystem'sperformance\nwithapotentialcontrolgroup.Thestudy'sbasisforprovingtheefficacyofthe\nexperimentalstrategywasstrengthenedbythemanipulation,control,and\npossiblyrandomassignmentofparticipantstowatchandreacttofiresin\nsimulatedscenarios.\nEnvironmentandParticipants\nThisstudywasconductedinClarin,Bohol.AccordingtoGoogleMaps,itis\nlocatedintheprovinceofBoholwhichis43.8kmawayfromTagbilaranCityvia\nCortes,Balilihan,Catigbian,andMacaasRoadtothenauticalhighwaytothe\ntownofClarinbyanaveragetimeof1hourand6mins.TheBureauofFire\nProtection(BFP)ofClarinBohol,aswellastheownersoflocalpublicandsmall\ncompanies,areamongthekeyparticipants.TheinvolvementoftheBFPgave\nimportantinsightsintofiresafetystandards,legalrequirements,andoperational\nissuesthatfirefightingdepartmentsencounter.Collaborationwithbusiness\nownersenabledathoroughunderstandingoftheirindividualfiresafety\nrequirements,infrastructurerestrictions,andpreparednesstousedigitalora\nCCTVcamerasophisticatedtoafiredetectionandtoalarm.Thethesiswriters’\nstudyhadnoparticipantssincenodatawascollectedfrompeople.Thefindings\nofthisstudywouldserveasafoundationforfutureresearchinthefieldsoffire\ndetectionandemergencyalarmsystems.\n\n31\nFigure2LocationMap(GoogleMap,2024)\nInstruments\nThethesiswritersfocusedonanalyzingafiredetectionsystemwithan\nalarminapracticalsituation.Themodelwasdevelopedusingdeeplearning\nframeworkssuchasRoboFlow,PyTorch,andGooglecolabratory,VisualStudio\nCodeforcreatingthesystem.Duringcontrolledfiresimulations,datawas\ncapturedusingcameras.Thesystemanalyzeddatafromfiretoidentifyflames.\nBycomparingthemodel'soutputwiththeactualfire,thethesiswriters’evaluated\nhoweffectivelyitdetectsfires.Thiscanleadtofasterfiredetectionand\nemergencyalarm,withthepotentialforevenbetterdetectionthroughcontinuous\nlearningofthedeeplearningmodel.Thiswouldallowadetailedassessmentof\nthesystem'seffectiveness.\nPerformanceMetrics\nToevaluatetheeffectivenessofthefiredetectionmodel,thisstudywas\nemployedseveralkeyperformancemetrics.Thesemetricsassessthemodel’s\nabilitytoaccuratelyidentifyfiresandminimizefalsealarms.\n\n32\nMeanAveragePrecision(mAP50)\nThismetriciscommonlyusedtoevaluatetheperformanceofobject\ndetectionmodels.Itmeasurestheaverageprecisionofthemodelacross\ndifferentclasses,consideringonlydetectionswithanIoUof50%orhigher.\nWhere:\nNisthetotalnumberofclasses.\nAP50i​istheAveragePrecisionat50%IoUforclass퐀.\nInthesystem,MeanAveragePrecisionor(mAP50)calculatedthe\naverageprecisionofobjectdetectionacrossdifferentclasses,consideringonly\ndetectionswheretheIoUwiththegroundtruthboundingboxis50%orhigher.\nThismetricprovidesamorelenientevaluationcomparedtomAP,which\nconsidersalllevelsofIoUoverlap.\nMeanAveragePrecision(mAP50-95)\nThismetricisusedtoevaluatetheperformanceofobjectdetectionmodels\nacrossarangeofIoUthresholds.Itcalculatestheaverageprecisionby\nconsideringdetectionswithIoUvaluesfrom50%to95%.\nWhere:\nNisthetotalnumberofclasses.\n\n33\nAP50−95i​istheAveragePrecisionacrossIoUthresholds\nfrom50%to95%forclass퐀.\nInthesystem,mAP50-95providesacomprehensiveevaluationofthe\nobjectdetectionmodel'sperformancebyconsideringitsaccuracyacrossarange\nofIoUthresholds,from50%to95%.Thismetricgivesinsightsintohowwellthe\nmodelperformsatdifferentlevelsofoverlapbetweenpredictedandgroundtruth\nboundingboxes.\nDatasets\nFireandSmokeImages\nThisdatasetcontainsimagesoffireandsmokecapturedindifferent\nsituations,suchasbuildingfiresandindustrialaccidents.Itisdividedintotwo\ncategories:smokeandfire.Eachtypeoffirehasuniquechallenges,makingthis\n\n34\nFigure3ModelDevelopment\ndatasetavaluableresourceforunderstandinghowfiresbehaveandhowwecan\nrespondtothem.Forexample,firesinbuildingscanspreaddifferentlydepending\nonthematerialsinside,showingwhyspecializedfirefightingtechniquesareso\nimportant.Bystudyingthesedifferentfirescenarios,wecanimprovefire\ndetectionandpreventionsystemstomakethemmoreeffective.\nThedatasetincludesatotalof9,848images,whicharedividedasfollows:\n6,894images(70%)fortraining,1,477images(15%)forvalidation,and1,477\nimages(15%)fortesting(Roboflow,n.d.).Thisstructuredsplitensuresawell-\nbalancedapproachtotraining,evaluating,andtestingfireandsmokedetection\nmodels,helpingimprovetheiraccuracyandreliability.\nProcedure\nA.ModelDevelopment\nDataCollectionandPreparation:\n\n35\nThethesiswritersgathereddataonfire-relatedimagesandannotated\nthemwithboundingboxestocreategroundtruthlabels.Thecollecteddatawere\nusedfortraining.\nModelSelection:\nInthispartthethesiswritersselectedthebestmodeltouseforthetraining\nofimagefiredetection.ThethesiswritersdecidedtoselectYOLOv9.\nIntegrationwithResponseSystem:\nThethesiswritersintegratethetrainedYOLOv9model,developing\ncommunicationprotocolsforseamlessinteraction.\nTrainingandValidation:\nThethesiswriterstrainedtheYOLOv9modelontheannotateddataset\nandvalidateditonaseparatedatasettooptimizehyperparametersandensure\naccuracy.\nTestingandDeployment:\nInthispart,thethesiswritertestedtheintegratedsystem'sperformance,\nincludingdetectionperformance,anddeployeditinareal-worldorsimulated\nenvironmentforoperationalvalidation.\nB.SystemDevelopment\nThestudyusedtheSystemDevelopmentLifeCycle(SDLC)asaguiding\nframework,basedonthestructureoutlinedinKyeremeh(2019)'spaper\n\"OverviewofSystemDevelopmentLifeCycleModels\".AccordingtoGillis(2019),\n\n36\nFigure4SystemDevelopmentLifeCycle\ntheSDLCmodeldescribesthesequentialstagesinvolvedindevelopingan\ninformationsystem,frominitialconceptiontothecodingoftheproposedsystem.\nThethesiswritersfollowedtheselogicalstepsasaguidetodevelopthestudy.\nPhasel.IdentifyingProblems,OpportunityandObjectives\nIntheinitialphase,thethesiswritersestablishedthegroundworkforthe\nfiredetectionsystem.Thisstageinvolvedcrucialplanningandanalysis.The\nthesiswritersdefinedtheresearchobjectives,outliningthegoalsforevaluating\nthesystem'saccuracyandresponsetimeinapracticalsetting.Byincreasing\nreactiontimesandincreasingtheeffectivenessofemergencyresponsesystems,\nthegoalwastoimprovefiresafetyprecautions.Possibilitiesexistinutilizing\ninnovativetoolssuchasYOLOv9forpreciseandquickidentificationoffireand\nemergencyalarmsystems.\nPhaseII.DeterminingHumanInformationRequirements\nInthisphase,thethesiswriterscomprehendedtheinformation\nrequirementsofthehumanoperatorswhomonitoredandinteractedwiththe\n\n37\nintegratedsystem.Datasourcesareidentified,includingCCTVcameravideo\nfeed.Toenableoperatorstomakewisedecisionsinemergencysituations,itis\nimportanttomakesuretheyhavefastaccesstoappropriatedata.\nPhaselIl.AnalyzingtheSystemNeeds\nInthisphase,thethesiswritersdiveddeeplyintothesystem'shardware.\nThisinvolvedanalyzingtheoptimalCCTVcamerasetup,consideringpotential\nbenefitsanddrawbacksofthesystem,andensuringreliablefiredetection.\nPhaseIV.DesigningtheRecommendSystem\nThisphaseintegratedsystem'sarchitectureisconceptualizedduringthe\ndesignprocess.Toguaranteesystemreliability,thisinvolvesdeterminingthe\ndataflowbetweencomponents,definingcommunicationprotocolsandinterfaces,\nandcreatingfail-safemethods.Reliabilityandacceptanceoffaultsarefurther\naspectsthatshouldbeincludedinthearchitecturetoreducetimeandincrease\noperationalreliability.\nPhaseV.DevelopingandDocumentingtheSystem\nInthisphase,thethesiswritersusedthedesignguidelinesasaguide,\nthesoftwarecomponentsoftheintegratedsystemaredevelopedduringthis\nphase.Toaidinsystemcomprehensionandexecution,thisincludes\nimplementingtheYOLOv9integrationmoduleandproducingdocumentation\nsuchasdataflowcharts,systemarchitecturaldiagrams,APIspecifications,and\nusermanuals.ThetoolsusedtodevelopthesystemaretheVSCode,Python\nLanguage,andthePyQT5Librarytoexecuteandrunthesystem.\n\n38\nPhaseVI.TestingandMaintainingtheSystem\nInthisphase,thethesiswritersevaluatedthesystem'seffectiveness.The\nintegratedsystem'sfunctionality,performance,anddependabilityarethoroughly\nevaluated.Tofindandfixanyproblemsorbugs,unittesting,integrationtesting,\nandsystemtestingaredone.Thesystemwasdesignedtofunctionproperly\nthroughouttimethroughongoingmaintenanceandmonitoring,with\nimprovementsandenhancementsprovidedasappropriate.\nPhaseVII.ImplementingandEvaluatingtheSystem\nInthisfinalphase,thethesiswritersdeployedtheintegratedsystemin\nthechosensettingandassesseditsfunctionalityinpracticalsituationsincluding\nthelaststage.Importantparametersincludingfiredetectionperformanceare\ntrackedandevaluated.Toconcludethecycleofsystemdevelopmentand\nevaluation,inputfromusersandparticipantswasobtainedtoidentifyareasthat\nrequiremoreimprovementandoptimization.\n\n39\nGANTTCHART\n\n40\nChapter2\nPRESENTATION,ANALYSIS,ANDINTERPRETATION\nThischapterfocusesonhowdataispresented,processed,and\ninterpreted.Thefirstportioncontainsanexplanation,executivesummary,and\ngraphicaldepictionsofthemodel'sdesign.Thenextpartdescribesandpresents\nthemodel'sperformanceregardingprecision,meanaverageprecision,andrecall.\nThemodel'sdesignisdiscussedinthechapter'sfinalpart.\n1.Whatisthemodel’sarchitecture?\nAmodelarchitectureisessentiallyablueprintforhowamachinelearning\nmodeloperates.Itexplainsthemodel'sstructure,whichincludesthelayers,\nconnections,andoperationsforprocessingdataandmakingpredictions.Model\narchitectureiscriticalinresearchandsystemdevelopmentsinceitdirectly\ninfluencesthemodel'saccuracy,speed,andabilitytoperformvarioustasks.\nAccordingtoGoodfellow,Bengio,andCourville(2018)intheirbookDeep\nLearning.“Thechoiceofarchitectureinfluencesthemodel'sabilitytolearn\n\n41\npatternsfromdataandgeneralizetonewscenarios.”Themodelarchitecture\nservesasthefoundationforeverymachinelearningsystem,directinghowdata\nisprocessedandpredictionsaremade,whichiscriticalforsuccessinresearch\nandsystemdevelopment.\nFigure5ArchitectureoftheModel\n\n42\nThethesiswriter'smaingoalistouseYOLOv9-tinytocreateamodel\ncapableofdetectingfire.YOLOv9-tinywaschosenbecauseitsarchitectureis\nthoughttobehighlyefficientforreal-timeobjectdetection,providinghigh\nperformancewhilerequiringminimumcomputationalpower.Figure5showsthe\narchitectureofthethesiswriters’proposedmodel.Ithasthreebasiccomponents:\naninputlayer,backbone,neck,andhead.\nTheinputlayerresizesimagesfromvideotoafixedshapeof640x640x3.\nThissizeindicatestheimage'swidth,height,andcolorchannels(red,green,and\nblue).Theinputlayerpreparesthetrainingimages,whicharethensentintothe\nbackboneforfeatureextraction.\nThebackboneofYOLOv9-tinyextractsessentialfeaturesprocessesthem,\nandsendsthegeneratedfeaturemapstotheheadthroughtheneckcomponent.\nThisbackbonepusheskeyinformationfromthedatathatcomesintogenerate\ndetailedfeaturemaps.TheELAN(EfficientLayerAggregationNetwork)serves\nastheprimaryprocessingblockinYOLOv9-tiny'sbackbone.Thisarchitecture\nimprovesthenetwork'slearningcapabilitiesbyusingexpand,shuffle,andmerge\noperationswhilemaintainingtheoriginalgradientflowforfasttraining.\nThedesignshowsabackbonemadeupofconvolutionallayers,ELAN\nblocks,andAConv(AverageConvolution)layers.AConvlayers,whichreplace\nmaxpooling,areusedtodownsamplethefeaturemaps.Theyminimizethe\nspatialsizeofthefeaturemapswhilepreservingtheirimportantproperties.Each\n\n43\nAConvoperationusuallyinvolvesconvolutionwithastrideof2totwicethe\nfeaturemapdimensions.\nTheSPPELANmoduleintheYOLOv9-tinyarchitectureimprovesthe\nnetwork'sabilitytosenseandanalyzespatialinformation.Thismoduleefficiently\nhandlesinputfeaturemapswithseparableconvolutions,loweringthenumberof\nparametersandcomputationalcostwhilepreservingspatialfeatureextraction\nquality.TheSPPELANmoduleusesskipconnectionstocombinecontextual\ninformationfromthecurrentandpriorfeaturemaps,ensuringthatthenetwork\ncollectsbothlocalandglobalfeatures.\nTheneck,whichislocatedbetweenthebackboneandthedetectinghead,\nfunctionsasafeatureextractorlayer.Itintegratesmulti-scaleinformationby\ncombiningfeaturemapsfromvariousstagesofthebackboneinanordered\nmethod.Insteadofmaxpooling,YOLOv9-tinyusesAConv(AverageConvolution)\ntobuildfixed-sizefeaturemapswhilepreservingimportantcontextualinformation.\nTheSPPELANmoduleusesamoreadvancedaggregatingapproach\ninsteadoftypicalspatialpyramidpooling.Thismethodusesefficientpath\naggregationtoimprovetheflowofinformation.ELANimprovescommunication\nbetweenlayersduringpathaggregationbycombiningfeaturemapsfromthe\ncurrentandpriorlevelstoprovideafullfeaturerepresentation.Thisdesign\nenablesYOLOv9-tinytostrikeabalancebetweenperformanceand\ncomputationaleconomy,makingitidealforreal-timeobjectdetection.\n\n44\nTheheadisthefinaldetectionlayerintheYOLOv9-tinyarchitecture,andit\ngeneratesexactpredictionsbasedonthefeaturemapsprovidedbythe\nbackboneandneckmodules.Thiscomponentisintendedtohandletask-specific\noutputssuchasobjectposition,confidencescores,andclasslabels.InYOLOv9-\ntiny,theheadmakesmulti-scalepredictionsusingfeaturemapsfromthe\nbackboneandneckphases.Thesefeaturemapsaredividedintothreelayersof\ndifferingsizestodetectobjectsonsmall,medium,andlargescales.\nTable1\nConfigurationofthehyperparametersusedduringtraining\nHyperparametersValue\nLearningRate0.01\nMomentum0.937\nWeight_Decay0.0005\nBatch_Size16\nImage_Size640x640\nEpochs100\nTable1containsthehyperparametersusedtotraintheYOLOv9-tiny\nmodel.Themodelwastrainedusingalearningrateof0.01,momentumof0.937,\nandweightdecayof0.0005.Thetraininglasted100epochs,withabatchsize16,\nandtheinputimageswerescaledto640×640.TensorBoardwasusedduring\ntrainingtokeeptrackofdata,evaluateloss,andrecordthemodel'sweightsat\n\n45\ntheendofeachepoch.Thishelpstomakethetrainingprocessrunsmoothlyand\neasilymonitored.\n2.Whatistheperformanceofthemodelintermsofthefollowingmetrics;\nModelperformancerelatestohowsuccessfullyamachinelearningmodel\nmeetsitsobjective,suchasaccuratelydetectingfireorsmoke.Itistypically\nassessedusingmetricssuchasaccuracy,mAP(meanAveragePrecision),\nprecision,andrecall,dependingonthejob.Forexample,inobjectdetection,\nperformancemetricsindicatehowsuccessfullythemodelrecognizesandlocates\nthingsinanimageorvideo.Jin,etal.(2021),thecreatorofKeras,statesinDeep\nLearningwithPython,\"Performanceevaluationisessentialforunderstandingthe\npracticalutilityofyourmodelandensuringthatitmeetsthespecificneedsofthe\napplication.\"\nFigure6TrainingandTestResults\n\n46\nAnF1-confidencecurveillustratestheF1scoreverticallyandconfidence\nhorizontally,indicatinghoweffectivelythemodelbalancesprecisionandrecallat\nvariousconfidencethresholds.Asdemonstratedinthefigureabove,themodel\nexcelsindetectingfires,earningthegreatestF1scorecomparedtosmoke\ndetection.Thethickdarkbluecurveshowstheoverallperformanceacrossall\nclasses,withapeakF1scoreof0.88ataconfidencelevelof0.364.Thisimplies\nthatwhenpredictionsareproducedwithaconfidencelevelof36.4%,themodel\nachievestheoptimalbalanceofprecisionandrecall.Beyondthispoint,theF1\nscoredropsasthemodelgainsconfidencebutlosesrecall,particularlywhen\ndetectingsmoke.\nFigure7TrainingandValidationLoss\nThetrainingandvalidationboxlosstrendsforthemodelduringthe\ntrainingphaseareshowninFigure7.Thelossvaluesaredisplayedonthe\nverticalaxis,andthenumberofepochsisrepresentedonthehorizontal.Asseen\nintheleftgraph,thetraininglosssignificantlydropsoverthefirst20epochsand\nthensteadilydeclinesuntilstabilizingatepoch80andlevelingoffnearer0.9by\n\n47\nepoch100.Likewise,ascanbeseeninthegraphontheright,thevalidationloss\nbeginsatalargerlevelthanthetraininglossandthendropsoffdramaticallyin\nthefirstfewepochs.Afterthat,itsteadilydeclinesuntilstabilizingatabout0.7\nfollowingepoch80.Theobservedpatternssuggestlittleoverfittingandshowthat\nthemodelislearningefficientlywithareasonablebalancebetweentrainingand\nvalidationloss.Asaresult,themodelisdeemedwell-trainedandappropriatefor\nobjectdetectioninthisinvestigationafter100epochs.\nThetablebelowshowsthemodel'sperformanceusingthemAPmetric.\nTheevaluationincludedatotalof9,848images,whichareseparatedintothree\nsets:atrainingdatasetof8,243images,avalidationdatasetof1,062images,\nandatestdatasetof543.Thesedatasetsaremeticulouslyproducedto\nguaranteethatthemodelwascompletelytrained,validated,andtested,\ndemonstratingitsefficacyandaccuracyinspottingobjects.Thetrainingdataset\nisusedtoteachthemodelhowtodetectobjectssuccessfully,whilethevalidation\ndatasetwasusedtotrackitsperformanceduringtrainingandfine-tunethe\nhyperparameters.Finally,thetestdatasetareutilizedtodeterminethemodel's\noverallaccuracy.Thisbreakdownguaranteesthatthemodeliscarefully\nexaminedforitsabilitytogeneralizeandproperlyrecognizeobjectsinunseen\ndata.\nTable2\nModelEvaluationonTestDataset\nMetricsScore(%)\n\n48\nmAP@0.588.5%\nmAP@.5:.9572.3%\nTable2showsthemodelarchitecture'soverallperformance.Thetrained\nmodelachievedamAP@.5scoreof88.5%andamAP@.5:.95scoreof72.3%.\nTheseresultsshowthatthemodelperformseffectivelyindetectingfireand\nsmoke,demonstratingitsdependabilityinthisspecificapplication.\n\n49\nFigure8ConfusionMatrix\nTheconfusionmatrixisaperformancemeasurementformachinelearning\nclassification(Sarang,2018).Eachrowinthematrixreflectstheactualclass(fire\nandsmoke),andeachcolumnrepresentstheexpectedclass.Thisheatmap\ndisplaysnormalizedfindings,makingiteasiertounderstandtheproportionsof\naccurateandmistakenpredictions.Accordingtothefigureabove,themodel\ndoesanexcellentjobofclassifying\"fire,\"properlyidentifying95%ofthe\"fire\"\ninstances.However,1%ofthefireinstancesweremisclassifiedas\"smoke,\"and\n4%wereincorrectlypredictedas\"background.\"For\"smoke,\"themodelhas\nmoredifficulty,correctlyidentifying82%oftheinstances,but18%were\nmistakenlylabeledas\"background.\"Finally,forthe\"background\"class,50%of\ntheinstanceswerecorrectlyclassified,buttheother50%wereconfusedwith\n\"smoke.\"Overall,themodelperformswellinthe\"fire\"category,butstruggles\nmoreinthe\"smoke\"and\"background\"categories,indicatingspacefor\ndevelopmentintheseareas.\nThefigureaboveshowsthattheprojectedcategoriesof“fires”and\n“smoke”havetherightpredictionrateof95%and82%respectively,indicating\nthatthemodelhasahighdegreeofaccuracy.\n3.Whatisthedesignofthesystemintermsof;\n3.1SystemArchitecture\nSystemarchitectureisthehigh-leveldesignorstructureofasystemthat\ndescribeshowitscomponentsinteracttoachieveagivenobjective.Itlaysouta\n\n50\nclearplanforarrangingthesystem,includinghardware,software,dataflow,and\nrelationshipsbetweencomponents.Systemarchitectureisimportantbecauseit\nspecifieshowasystemworks,maintainsitsstabilityandscalability,and\nestablishesthegroundworkforefficientdevelopment,maintenance,and\nupgrades,especiallyinsafety-criticalsystemssuchasfiredetection.According\ntoBass,Clements,andKazman'sSoftwareArchitectureinPractice(2012),\n\"architecturedefinesthestructureandbehaviorofasystem,ensuringthatit\nmeetsbothtechnicalandbusinessgoals.\"\n\n51\nFigure9SystemArchitecture\nFigure9showsthesystemarchitectureforfiredetectionwithYOLOv9-t.\nTheprocessstartswithcapturinglivevideofootagefromCCTVcameras\ndeployedinbuildingsorbusinesses.Thecollectedframesareeventually\npreprocessedtocomplywiththeYOLOv9-tmodel'sinputrequirements,which\nincludescalingandnormalization.TheYOLOv9-tmodelanalyzesthe\npreprocessedframesanddetectsfireusingitsefficientbackboneanddetection\nhead.Ifafireisdetected,thesystemsoundsanalarmtoinformthebuilding's\nresidents.Ifnofireisdetected,thesystemcontinuestomonitorthelivevideo\nfeedinrealtime.Thisarchitectureensuresaccurateandefficientfiredetection,\nwhichimprovessafetyinofficeandbuildingscenarios.\n3.2SystemDesign\nSystemdesignistheprocessofspecifyingthespecificcomponents,\nmodules,interfaces,anddataflowofasystemsothatitcanperformproperly.\nWhilesystemarchitectureprovidesahigh-levelstructure,systemdesignfocuses\nonthespecificfeaturesrequiredforthesystemtofunctionefficiently.System\ndesignisessentialbecauseitdescribeshoweachcomponentofasystemruns\nandinteracts,ensuringthatthesystemisefficient,scalable,anduser-friendly\nwhileachievingitsobjectives.Itistheblueprintfortransforminghigh-level\narchitectureintoapractical,real-worldapplication.AccordingtoSommervillein\nSoftwareEngineering(2011),\"Systemdesignbridgesthegapbetweenuser\n\n52\nClickthe\nvideo\nselection\ntofeed.\nAfterclicking,\nthereisan\noptionhowto\nfeedavideo\nwhetheryou\ncanchoosea\nvideofile,a\ncameraurlor\ninalaptop\ncamera.\nAfterclicking\nwhichofthat\noptionyou\nhave\nchosen,\nthereisan\noptionalso\npop-uptoset\nanameof\nrequirementsandthesystem'simplementation,detailinghowtherequirements\narefulfilled.\"\nOpentheapplication\n\n53\nHereisthe\nFYRVISION\nSYSTEM\nlookslike,\nthereare\nfourgridin\nthemonitor\ntofeed\ndifferent\ncamera\nvideosorlive\ncamera.\nThisnavigationshowsthelogofthesystemwherein,thesystem\ndetectsfire.Itwoulddisplaytextforthedetectedfirewithtimeand\ndate.\nFigure10SystemDesign\nFigure10.showsthesystemdesignofthefiredetectionmodelbasedon\nYOLOv9-tisbuilttorapidlyhandlelivevideofeedsfromCCTVcameras\ndeployedinbuildingsorworkplacesinordertodetectfireinrealtime.The\nsystemstartswiththeopentheapplication,clickthevideoselectiontofeed\ndifferentcameravideos.Afterthatchoosethe3optionstofeedvideoincludinga\n\n54\nvideofile,acameraurlandalaptopcamera.Then,afteryouclicktheoptionthat\nyouhavechosenthereisanpop-upmessagethatyoucansetanameofthe\npositionofthecameraofthatcertainvideos.Finally,theFYRVISIONSYSTEM\nuserinterfaceafterfeedingallthegridsandnamesofthepositionsofthecamera\nandcertainvideos.Thesystemmonitorhasbeenfeedallthegridsandthe\nmodelofthesystemaccuratedetectingfireandsmokeafterfeedingvideos.\n4.Whatistherequirementsspecificationoftheproposedsystemintermsof;\n4.1FunctionalRequirements\nFunctionalrequirementsspecifythespecifictasksorfunctionsthata\nsystemmustcarryoutinordertoachieveitsobjectives.Thesearethesystem's\n\"what\"—whatitshoulddo,whatfeaturesitshouldhave,andwhatactionsit\nshouldperformingivencircumstances.Functionalrequirementsarecriticalfor\nensuringthatthesystemproducestherequiredoutputsandrunsasintended.\nTheylaythegroundworkfordesign,development,andevaluation,ensuringthat\nthefinishedproductmeetsthedemandsandobjectivesoftheusers.\"Functional\nrequirementsdescribesystembehaviororfunctions,focusingonwhatthe\nsystemshoulddotomeetuserneeds.\"(IanSommervillestatesinSoftware\nEngineering2011).\n\n55\nFigure11FunctionalRequirements\nFigure11showsthefunctionalrequirementsofthefiredetectionsystem\nthatusesYOLOv9-t,whicharedesignedtoensurereal-time,efficient,anduser-\nfriendlyoperationinbuildingorofficeenvironments.Thesystemallowsusers,\nsuchasbuildingadministratorsorsecuritypersonnel,toviewlivecamerafeeds\nwhilesoftwareanalyzesthefootagetodetectfireorsmokeinseconds.Itenables\ntheefficientmanagementofmultiplecameras,makingitperfectforlargeareas.\nWhenafireisdetected,thesystemsendsvisualandaudiblealerts,providing\nessentialinformationforpromptaction.Theuser-friendlyinterfacesimplifies\nconfigurationbyallowingyoutoaltercamerasettings,detectionthresholds,and\nsystemmonitoring.Themodulardesignenableseasyupdatesandmaintenance\nwithoutdisruptingoperations.Overall,thesystemisdesignedtobedependable,\nresponsive,andadaptabletochangingenvironmentalconditions,allowingusers\ntomaintainsafetymoreefficientlyandeffectively.\n4.2Non–FunctionalRequirements\nNon-functionalrequirementsspecifythequalitycharacteristicsor\nrestrictionsofasystemratherthanthespecifictasksitmustdo.Theydescribe\n\n56\nThesystemshouldprocessvideo\nframesanddetectfirewithin5seconds\nofitsappearanceinthefeed.The\nsystemmustbeabletoprocessdatain\nrealtimewithminimaldelays.\nThesystemshouldbeabletohandle\nfourcamerafeedssimultaneously\nwithoutfailing.\nThesystemshouldfunctionreliably\nunderavarietyofenvironmental\nsituations,suchaschangingroom\nlighting.\nThesystemshouldbeavailablearound\ntheclock,withminimaldowntime.It\nshouldbeabletooperatecontinuously\nforextendedperiodsoftimewithout\nsevereinterruptions.\nthesystem'sperformance,dependability,usability,andotherqualities.Non-\nfunctionalrequirementsareequallysignificantasfunctionalrequirements\nbecausetheyinfluencethesystem'soverallquality,performance,anduser\nhappiness.Theyassistdevelopersindesigningasystemthatisnotonly\nfunctional,butalsoefficient,dependable,anduser-friendly.\"Non-functional\nrequirementsarecriticaltoensuringthatthesystemasawholewillmeetuser\nexpectationsanddeliveranoptimalexperience.\"(IanSommervillestatesin\nSoftwareEngineering,2011).\nTable3\nNon–FunctionalRequirements\nNon–FunctionalNon–FunctionalRequirements\nRequirementsDescription\nNo.\nNFR\n1\nNFR\n2\nNFR\n3\nNFR\n\n57\nThesysteminterfacemustbesimpleto\nuse,allowingforstraightforward\ncameraandsystemconfiguration.The\ninterfaceshouldprovideclear\ninformationaboutsystemstatus,fire\ndetectionresults,andalertnotifications.\nThesystemshouldbemodularforeasy\nmaintenanceandupgrades.Updatesto\nthefiredetectionmodelandnew\nfunctionalityshouldbepossiblewithout\nimpactingsystemoperations.\nThesystem'scomputingresources\nshouldbeusedefficiently,reducing\nCPUandmemoryusewhile\nmaintainingexcellentperformance.It\nshouldalsobeenergy-efficient,\nparticularlyifusedinregionswith\nlimitedresources.\n4\nNFR\n5\nNFR\n6\nNFR\n7\nTable3showsthefiredetectionsystem'snon-functionalrequirements\nemphasizetheimportanceofdependability,efficiency,anduserfriendliness.The\nsystemismeanttodetectfirerapidly,evaluatingvideofeedsinreal-timeand\nrecognizingitwithin5secondsofitsdebut.Itcanhandlenumerousvideofeeds\natthesametime,ensuringuninterruptedoperationeveninvaryingenvironmental\nconditions,suchaschangingroombrightness.Thesystemisdesignedfor\ncontinuousoperation,withlowinterruptions,makingitoptimalforlong-term\nmonitoring.Itsinterfaceisbasicandstraightforward,allowinguserstoconfigure\ncameras,examinesystemstatus,andreceivealerts.Furthermore,thesystemis\n\n58\nmodular,whichallowsforsimpleupdatesandmaintenancewithoutstopping\noperations.\n5.Whatisthecomparisonwithothermodelsintermsofperformance?\n5.1SSD(SingleShotDetector)\nModelcomparisonisassessingandevaluatingvariousmachinelearning\nordeeplearningmodelstoidentifywhichisbestsuitedforacertaintaskor\nresearchaim.Thiscomparisonistypicallybasedonperformancemetrics,\nefficiency,flexibility,andotherpertinentfactors.Modelcomparisonisvitalto\nconfirmthatthechosenmodelmeetstheproject'srequirements.Inthissituation,\nYOLOv9-twaschosenoverSSDduetoitshigheraccuracy,adaptability,and\nefficiency,makingitmoredependablefordetectingfiresinbuildingsoroffices.\n\"Comparingmodelsprovidescriticalinsightsintotheirapplicabilityinspecific\nscenariosandguidestheselectionprocessforreal-worldimplementation\"(Han\netal.,2021).\nTable4\nModelComparisonPerformance\nModelmAP@.50mAP@.50-.95\nYOLOv9t0.8850.723\nSSD0.8630.541\nTable4comparestheperformanceofYOLOv9-tandSSDinfiredetection.\nTheYOLOv9-tmodelislightweight,efficient,andveryaccurate,withmAP@50of\n\n59\n88.5%andmAP@50-95of72.3%,whereasSSDhasmAP@50of86.26%and\nmAP@50-95of54.07%.YOLOv9-tclearlyoutperformsSSDinthemAP@50and\nmAP@50-95measures.ThemAP@50-95score,whichassessesdetection\nprecisionovernumerousIoUthresholds,demonstratesYOLOv9-t'senhanced\nabilitytodetectobjectsofdifferentsizeswithgreateraccuracy.Thisimproves\nYOLOv9-t'sperformanceforcomplexfiredetectionjobs,especiallyindynamic\ncontextssuchasbuildingsorworkplaces.WhileSSD(SingleShotMultiBox\nDetector)isanobjectdetectionmodelthatquicklyidentifiesobjectsinimagesor\nvideosbypredictingboundingboxesandclasslabelsinasinglepassthrough\nthenetwork.SSDisaone-stagedetector,makingitfasterbutsometimesless\naccurate,especiallyfordetectingsmallobjects.Itusesmultiplefeaturemapsat\ndifferentscalestoimprovedetectionperformance,isasimplertypethatperforms\nwell,theYOLOv9-t'ssuperioraccuracyandefficientlightweightconstruction\nmakeitthepreferablechoiceforreal-timefiredetectionapplications.\nYOLOv9-t'sarchitectureisspecificallydesignedtobelightweight,resulting\ninquickprocessingandrapidinferencewithoutsacrificingdetectionquality.The\nuseofELANblocksandRepNCSPELAN4modulesenhancesfeatureextraction\nandscale-awaredetectionwhilekeepingmodelcomplexitymanageable.This\nmakestheYOLOv9-tperfectforreal-timeapplicationslikefiredetectionin\nbuildingsandworkplaces,wherespeedandaccuracyarecritical.WhileSSDis\nverysimpleandefficientforsimplerjobs,itslowermAP@50-95scoreshows\nlimitationsintacklingdifficultdetectingscenarioswithvariedobjectdimensions.\nTheYOLOv9-t'slightweightdesign,togetherwithitsexceptionalperformancein\n\n60\ndetaileddetectiontasks,distinguishesitasamoreeffectiveandpracticalsolution\nforfiredetectionsystems.\nChapter3\nSUMMARY,CONCLUSION,ANDRECOMMENDATIONS\nSummary\nThisstudyaimedtodevelopareal-timefiredetectionsystembasedon\nYOLOv9.Itusedafullyexperimentalapproach,collectingandpreprocessing\ndatasetsusingthePyTorchframework.Themodelwastrainedandtestedonfree\nGPUresourcesgivenbyGoogleCollaboratory.\n\n61\nThisstudyexaminedthesystemarchitecture,components,anddesignof\nthesuggestedfiredetectionmodel.Italsoexploredthemodel'sperformance\nusingkeymetricsincludingmeanaverageprecision(mAP@.5andmAP@.5:.95).\nFinally,thestudyintendedtodisplaythefiredetectionsystemdesignand\ndemonstrateitseffectivenessindetectingfireandsmokeintestimages.\nFindings\nAfteranalyzingthedata,thethesiswriter’sfoundthefollowing:\n1.TheYOLOv9-t-basedfiredetectionmodelcontainsaninputlayerthat\nprocesses640x640x3pictures.Thebackboneeffectivelyextractsfeatures\nusingconvolutionallayers,ELAN1Blocks,AConvlayers,and\nRepNCSPELAN4Blocks.TheneckcombinesSPPELANBlocks,\nupsampling,andconcatenationtogeneratemulti-scalefeaturemaps(P3,\nP4,andP5).Finally,theheadgearusesDualDetectlayerstoidentify\nthingsonsmall,medium,andlargescales,resultinginpreciseand\nefficientfireandsmokedetection.\n2.Themodelperformedwellinrecognizingandidentifyingfireandsmoke,\naswellaspredictingboundingboxeswithhighconfidence.Itachieveda\nmAP@0.5scoreof88.5%andamAP@0.5:0.95scoreof72.3%,\nindicatingreliableimageandvideoanalysisperformance.\n3.Themodelwascreatedtodetectfireandsmokecorrectly,anditcanbe\nusedtoactivatealarmsorsafetysystemswhenafireisdetected.The\n\n62\nYOLOv9-tfiredetectionsystemisdesignedforreal-timemonitoringthatis\nbothefficientanddependable.Itsarchitecturetakesvisualinputfrom\nmanycamerasandusesthelightweightYOLOv9-tmodeltodetectfireat\nvariousscaleswithgreataccuracy.Detectedoccurrencesgenerateinstant\nnotifications,ensuringpromptreplies.Thedesignfeaturesaneasy-to-use\ninterfaceforcameraconfigurationandreal-timemonitoring,aswellasa\ndisplayofdetectionresultsandsystemstatus.Overall,thesystemis\ndesignedfor24hourmonitoringinbuildingsorworkplaces,ensuring\nscalability,usability,andconsistentperformance.\n4.Functionalrequirementsincludedreal-timevideoframeprocessingto\ndetectfirewithinfiveseconds,simultaneoushandlingofuptofourcamera\nfeeds,andquicknotificationswhenfireisdetected.Thesystemalsohasa\nuser-friendlyinterfaceforsetupcameras,viewingdetectionresults,and\nmonitoringsystemcondition.Non-functionalrequirementsensurethatthe\nsystemisreliableandefficient.Itmustworkcontinuouslywithlow\ndowntime,functioninavarietyofenvironmentalcircumstancessuchas\nchangingillumination,andusecomputationalresourcesefficientlyto\nmaintainperformancewhileconsuminglessenergy.Thesecriteriawork\ntogethertocreateafiredetectionsystemthatisdurable,scalable,and\neasytouseinofficeorbuildingcontexts.\n5.Intermsofperformance,theYOLOv9-tmodeloutperformsSSD(Single\nShotDetector)forfiredetection.YOLOv9-thasamAP@50of88.5%and\n\n63\namAP@50-95of72.3%,demonstratingitsabilitytodetectfirecorrectlyat\nallscalesandsituations.Incomparison,SSDhasamAP@50of\n86.26%andamAP@50-95of54.07%.WhileSSDperformssomewhat\nbetterinthemAP@50metric,whichmeasuresdetectionprecisionata\nsingleIoUthresholdof0.5,YOLOv9-tsurpassesSSDinthemore\ncomprehensivemAP@50-95metric.ThisdemonstratesYOLOv9-t's\nimprovedadaptabilityandprecisionacrosschangingIoUthresholds,\nmakingitamoreefficientanddependablesolutionforfiredetectionjobs,\nespeciallyincomplicatedcontexts.\nConclusion\nThethesiswritersconcludedthattheYOLOv9-tnetworkdesign\nwashighlyeffectiveatdetectingfireandsmoke.Themodelwascreatedand\nevaluatedusingtheGoogleColabplatformandthePyTorchframework,witha\ndatasetoffireandsmokeimagesasthebasis.Basedonthefindings,thethesis\nwriterssuccessfullycreatedadeeplearningmodelcapableofproperlydetecting\nfireandsmoke,whichmaybelinkedintosafetysystemstotriggeralarmsor\npreventiveprocedures.\nRecommendations\nThethesiswritersprovidedthefollowingrecommendations:\n1.AdjusttheYOLOv9-tdesigntoimproveitsabilitytodetectfireandsmoke\nincomplicatedandtoughconditions.\n\n64\n2.Trainthemodelusingalargerdatasetandmoreepochstoimproveits\nperformanceandreliability.\n3.Innovatethemodelforpracticalapplicationinbuildingsandoffices,\nmakingsureitcanadjusttovariedspacelayoutsandlighting\ncircumstances.\n4.Thesystemshouldincreasereal-timedetectionacrossnumerouscamera\nfeedsandincludeautomaticnotificationsforbetterfunctioning.Itmustbe\nadjustedforefficiencyanddependability,ensuringpreciseperformance\nunderavarietyofenvironmentalcircumstances.Inaddition,thesystem\nshouldprovideasimpleinterfaceforconfigurationandmonitoring.\n5.TheYOLOv9-tmodelshouldbefurtheroptimizedtokeepitslightweight\narchitecturewhileenhancingitsaccuracy,particularlyinthemAP@50\nmeasure.Furthermore,trainingthemodelonmorediversedatasetsmay\nimproveitscapacitytogeneralizeacrossmultiplecircumstances.\nComparingfuturedevelopmentstoothersophisticatedmodelscanhelpto\nimproveperformanceandsetbenchmarks.\nDEFINITIONOFTERMS\nAccuracy.Itistheperformancemetricsthatdescribehowthemodel\nperformsacrossallthedatasets.Itreferstothepercentageofcorrectpredictions\nforthetestdataset.\nAnalysis.Itreferstotheanalyzingprocessindetectingfiresonthe\nimage/videospresentinthecameraframeinreal-timedata.\n\n65\nArtificialIntelligence.Abranchofcomputerscienceconcernedwith\ncreatingintelligentagents,whicharesystemsthatcanreason,learn,andact\nautomatically.NeuralnetworksareapowerfultoolusedinAIforvarioustasks,\nincludingimagerecognition.(StuartRussellandPeterNorvig.Artificial\nIntelligence:AModernApproach.PearsonEducationLimited,2016)\nComputerVisionAlgorithms.Programsdesignedtoextractinformation\nfromdigitalimagesandvideos,oftenusedforobjectdetection,classification,and\ntracking.Thesealgorithmsleveragetechniqueslikeimagesegmentation,feature\nextraction,andpatternrecognitiontoanalyzevisualdataandidentifyobjectsor\neventswithinanimageorvideosequence.Inthecontextoffiredetection,\ncomputervisionalgorithmscanbeusedtopre-processimagesorvideosbefore\nfeedingthemintoaCNNmodelforfireidentification.(RichardSzeliski.Computer\nVision:AlgorithmsandApplications.Springer-Verlag,2011)\nConvolutionalNeuralNetworks(CNNs).Aspecifictypeofdeeplearning\nmodelparticularlywell-suitedforimagerecognitiontasks.CNNsutilizea\nspecializedarchitecturewithconvolutionallayersthatcanefficientlyextract\nspatialfeaturesfromimages.BytrainingaCNNonalargedatasetoflabeled\nimagescontainingfireandnon-firescenarios,themodelcanlearntoidentify\npatternswithhighaccuracy.Thiscapabilityiscrucialfortheproposedfire\ndetectionsystem(YannLeCun,YoshuaBengio,andGeoffreyHinton.“Deep\nLearning.”Nature521.7553(2015):436-444)\nDataset.Itisasetofgathereddataofthefireimagesinthedatabase.\n\n66\nDeepLearning.AsubfieldofAIthatutilizesartificialneuralnetworkswith\nmultiplelayerstolearnfromlargeamountsofdata.Deeplearningalgorithmscan\nlearncomplexpatternsandrelationshipswithindata,enablingthemtoperform\ntaskslikeimagerecognitionwithhighaccuracy.ConvolutionalNeuralNetworks\n(CNNs)areaspecifictypeofdeeplearningmodelparticularlywell-suitedforthis\npurpose.(IanGoodfellow,YoshuaBengio,andAaronCourville.DeepLearning.\nMITPress,2016)\nDetectionAccuracy.Itreferstotheperformanceofthesystemsthatcan\ncorrectlyidentifyandlocatefiresinimagesorvideos.\nDigitalCamera.Referstothecamerathatisusedforcapturingimagesor\nvideosoffires.\nFireDetectionDataset.Acollectionofdigitalimagesspecificallycurated\nfortrainingaCNNmodelforfireidentification.\nFireOutbreak.Anuncontrolledburningeventthatposesathreattolife\nandproperty.\nFlowchart.Itshowsthesequentialprocessforanumberoffeatures,\nincludingthecreationofsafetyalerts,fireidentification,imageprocessingoffires,\nandemergencyalarmsystem.Theseflowchartsensureclarityand\ncomprehensionforallpartiesinvolvedinthecreation,implementation,and\noperationofthesystembygraphicallyrepresentingtheflowofdataandactions.\n\n67\nFYRVISION.Afiredetectionsystemthatusesartificialintelligenceand\ncomputervisiontodetectfireandsmokeinrealtimethroughvisualanalysis.It\ncombinesinnovativetechnologytodetectfiresmorequicklyandaccurately.\nGoogleCollaboratory.Theenvironmentwherethemodelwastrainedand\nevaluated.\nHaarCascade.Atoollanguageforatechnologythatcandetectand\nidentifyfires.\nInputimagesorvideoframes.Thedatabeinginputtedisusedfor\nanalyzingtherecognitionofanimage.\nNeuralNetworks.Afamilyofalgorithmsinspiredbythestructureand\nfunctionofthehumanbrain.NeuralNetworksconsistofinterconnectednodes\n(artificialneurons)thatprocessinformationbytransmittingsignalsbetweenthem.\nByadjustingtheconnectionsbetweenthesenodesthroughatrainingprocess,a\nneuralnetworkcanlearncomplexpatternsfromdata.(IanGoodfellow,Yoshua\nBengio,andAaronCourville.DeepLearning.MITPress,2016)\nOpenCV.Atoolthatcontainsthealgorithmsforthesystem.\nPerformanceMetrics.Itreferstothemeasurementsusedtoevaluatehow\nwellthesystemperforms,suchasmAP50,mAP50-95,andreliability.\nPyQt5.IsaPythonpackagethatimplementsPythonbindingsforQt,a\npopularcross-platformapplicationframework.Itenablesdeveloperstoconstruct\ndesktopprogramswithgraphicaluserinterfaces(GUIs)thatarebothcurrentand\n\n68\nplatformneutral.PyQt5isbasedonQtversion5,anditprovidesalloftheQt\nframework'scapabilities,modifiedforPython.\nReal-time.Itistheactualsituations/happeningsoftheenvironmentwith\nfires,andtime-to-timecapture.\nSystemArchitecture.Thesystemarchitectureaimstoprovidereal-time\nidentifyingfiresandsafetyalertsbyemergencyalarms.\nSystemPerformance.Itistheoverallprogressofthefireidentification\nsystem.\nTraditionalFireDetectionTechniques.Methodsforidentifyingfiresthat\nrelyonhumanobservationorbasicsensorsareknownforpotentialdelaysin\nresponse.Thesetechniquescanincludesmokedetectors,heatdetectors,and\nmanualfirealarms.Whilethesemethodsplayacrucialroleinfiresafety,human\nlimitations(fatigue,distraction)andsensorlimitations(falsealarms,slow\nresponsetospecificfiretypes)canhindertheireffectiveness.\nTestingfindings.Itistheactualtestingresultsorobservationsobtained\nfromthetestingphaseofthefiredetectionandemergencyalarmsystem.\nREFERENCES\nAlkhatib,A.A.(2014).Areviewonforestfiredetectiontechniques.International\nJournalofDistributedSensorNetworks,10(3),597368.\n\n69\nAlquorabah,H.,Muneer,A.,&Fati,S.M.(2021).Asmartfiredetectionsystem\nusingIoTtechnologywithautomaticwatersprinkler.InternationalJournal\nofElectrical&ComputerEngineering(2088-8708),11(4).\nAvazov,K.,Mukhiddinov,M.,Makhmudov,F.,&Cho,Y.I.(2021).Firedetection\nmethodinsmartcityenvironmentsusingadeep-learning-based\napproach.Electronics,11(1),73.\nBass,L.,Clements,P.,&Kazman,R.(2012).SoftwareArchitectureinPractice:\nSoftwareArchitectPractice_c3.Addison-Wesley.\nBu,F.,&Gharajeh,M.S.(2019).Intelligentandvision-basedfiredetection\nsystems:Asurvey.Imageandvisioncomputing,91,103803.\nCaliwan,C.L.(2024,March).BFP:Fireincidentsup25%infirst2monthsof\n2024.PhilippineNewsAgency(PNA).\nGeorgiades,G.,Papageorgiou,X.S.,&Loizou,S.G.(2019,April).Integrated\nforestmonitoringsystemforearlyfiredetectionandassessment.In2019\n6\nth\nInternationalConferenceonControl,DecisionandInformation\nTechnologies(CoDIT)(pp.1817-1822).IEEE.\nGoyal,S.,Shagill,M.,Kaur,A.,Vohra,H.,&Singh,A.(2020).Ayolobased\ntechniqueforearlyforestfiredetection.Int.J.Innov.Technol.Explor.\nEng,9,1357-1362.\n\n70\nHan,G.,Zhao,J.,Zhang,L.,&Deng,F.(2024).ASurveyofHuman-Object\nInteractionDetectionWithDeepLearning.IEEETransactionson\nEmergingTopicsinComputationalIntelligence.\nHeaton,J.(2018).Iangoodfellow,yoshuabengio,andaaroncourville:Deep\nlearning:Themitpress,2016,800pp,isbn:0262035618.Genetic\nprogrammingandevolvablemachines,19(1),305-307.\nHsu,W.L.,Jhuang,J.Y.,Huang,C.S.,Liang,C.K.,&Shiau,Y.C.(2019).\nApplicationofInternetofThingsinakitchenfirepreventionsystem.\nAppliedSciences,9(17),3520.\nJayashree,S.,&Janeera,D.A.(2016).Real-timefiredetection,alertingand\nsuppressionsystemusinglivevideosurveillance.ImpJInterdiscipRes\n(IJIR),2(7),595-600.\nJin,H.,Chollet,F.,Song,Q.,&Hu,X.(2023).Autokeras:Anautomllibraryfor\ndeeplearning.JournalofmachineLearningresearch,24(6),1-6.\nKhan,F.,Xu,Z.,Sun,J.,Khan,F.M.,Ahmed,A.,&Zhao,Y.(2022).Recent\nAdvancesinSensorsforFireDetection.Sensors(Basel,Switzerland),\n22(9),3310.https://doi.org/10.3390/s22093310\nKhan,H.A.,Kalpana,G.,Nishanti,G.,&Aarthi,N.R.(2023).AUTOMATICFIRE\nDETECTION,INDICATIONANDCONTROLLINGSYSTEMFOR\nCOMMERCIALBUILDINGUSINGPROGRAMMABLELOGIC\nCONTROLLER.JournalofPharmaceuticalNegativeResults,3350-3362.\n\n71\nKim,B.,&Lee,J.(2019).Avideo-basedfiredetectionusingdeeplearning\nmodels.AppliedSciences,9(14),2862.\nKruchten,P.B.(1995).The4+1viewmodelofarchitecture.IEEEsoftware,12(6),\n42-50.\nMoumgiakmas,S.S.,Samatas,G.G.,&Papakostas,G.A.(2021).Computer\nvisionforfiredetectiononUAVs—Fromsoftwaretohardware.Future\nInternet,13(8),200.\nNarkhede,S.(2018).Understandingauc-roccurve.Towardsdatascience,26(1),\n220-227.\nOkoroIsreal,C.,&Omokaro,I.(2017).Amodelofautomaticfiredetectionand\nsuppressionsystemwithimprovedefficiency.AmericanJournalof\nEngineeringResearch,6.\nRehman,A.,Qureshi,M.A.,Ali,T.,Irfan,M.,Abdullah,S.,Yasin,S.,&Wegrzyn,\nM.(2021).Smartfiredetectionanddeterrentsystemforhumansaviorby\nusinginternetofthings(IoT).Energies,14(17),5500.\nRoboflow.(n.d.).SmokeandFireDataset(Version2).RoboflowUniverse.\nhttps://universe.roboflow.com/detection-e83li/smokeandfire/dataset/2.\nSarvari,A.,&Mazinani,S.M.(2019).Anewtunnelfiredetectionand\nsuppressionsystembasedoncameraimageprocessingandwatermist\njetfans.Heliyon,5(6).\n\n72\nSommerville,I.(2011).Softwareengineering(ed.).America:PearsonEducation\nInc.\nTalaat,F.M.,&ZainEldin,H.(2023).Animprovedfiredetectionapproachbased\nonYOLO-v8forsmartcities.NeuralComputingandApplications,35(28),\n20939-20954.\nTeja,D.,Kiran,M.S.,Sudheer,A.V.,KumarReddy,I.A.,&Jyothi,K.(2022).IoT\nbasedfiredetectionandautomaticwatersprinklersystem.International\nJournalofEngineeringAppliedSciencesandTechnology,6(12),312-317.\nWang,C.Y.,Yeh,I.H.,&MarkLiao,H.Y.(2025).Yolov9:Learningwhatyou\nwanttolearnusingprogrammablegradientinformation.InEuropean\nConferenceonComputerVision(pp.1-21).Springer,Cham.\nZang,X.,Liu,W.,Wu,D.,Pan,X.,Zhang,W.,Bian,H.,&Shen,R.(2023).\nContemporaryfiresafetyengineeringintimberstructures:Challengesand\nsolutions.Fire,7(1),2.\n\n73\nAPPENDICES\nATransmittalLetters\n\n74\n\n75\nTHESISWRITER’SBIODATA\n\n76\nEULYSEST.BETASOLO\nCANMAYADIOT,SAGBAYAN,BOHOL\n09999692825\n6.PERSONALPROFILE\nDateofBirth:June6,2003\nPlaceofBirth:CanmayaDiot,Sagbayan,Bohol\nCitizenship:Filipino\nSex:Male\nAge:21\nCivilStatus:Single\nReligion:RomanCatholic\nFather’sName:EusibioT.Betasolo\nMother’sName:AlmaT.Betasolo\n7.EDUCATIONALATTAINMENT\nSeniorHighSchool:SanAgustinNationalSeniorHighSchool\nSanAgustin,Sagbayan,Bohol\n2019-2021\nJuniorHighSchool:SanAgustinNationalJuniorHighSchool\nSanAgustin,Sagbayan,Bohol\n2015-2019\nElementary:CanmayaDiotElementarySchool\nCanmayaDiot,Sagbayan,Bohol\n2009-2015\nTHESISWRITER’SBIODATA\n\n77\nJOHNDYVINCENTC.OSIO\nTUNGOD,INABANGA,BOHOL\n09092224177\nI.PERSONALPROFILE\nDateofBirth:December07,2000\nPlaceofBirth:Tungod,Inabanga,Bohol\nCitizenship:Filipino\nSex:Male\nAge:24\nCivilStatus:Single\nReligion:RomanCatholic\nFather’sName:VicenteM.Osio\nMother’sName:EstrellaC.Osio\nII.EDUCATIONALATTAINMENT\nSeniorHighSchool:SaintPaul’sAcademyofInabanga,Bohol,Inc.\nPoblacion,Inabanga,Bohol\n2019-2021\nJuniorHighSchool:SaintPaul’sAcademyofInabanga,Bohol,Inc.\nPoblacion,Inabanga,Bohol\n2013-2019\nElementary:InabangaSouthCentralElementarySchool\nPoblacion,Inabanga,Bohol\n2007-2013\nTHESISWRITER’SBIODATA\n\n78\nMARYJHANELYR.CEÑAL\nBACANI,CLARIN,BOHOL\nI.PERSONALPROFILE\nDateofBirth:October21,2002\nPlaceofBirth:Bacani,Clarin,Bohol\nCitizenship:Filipino\nSex:Female\nAge:22\nCivilStatus:Single\nReligion:SeventhDayAdventist\nFather’sName:FelipeP.Ceñal\nMother’sName:MarifelR.Ceñal\nII.EDUCATIONALATTAINMENT\nSeniorHighSchool:MaterDeiCollege\nCabulijan,Tubigon,Bohol\n2019-2021\nJuniorHighSchool:NahawanNationalHighSchool\nNahawan,Clarin,Bohol\n2015-2019\nElementary:BacaniElementarySchool\nBacani,Clarin,Bohol\n2009-2015"
  },
  {
    "filename": "1765885301930-Figures.pdf",
    "originalName": "Figures.pdf",
    "text": "\n\nTimestamp\nName\nCourse\nYear\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I don\nt understand the topic. \nI apply what I\nve learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorial\ns content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\n0.00\n0.25\n0.50\n0.75\n1.00\n1.25\n1.50\n1.75\n2.00\nFigure 1: Missing Responses per Survey Item\n\nBSES\nBEED\nBSHM\nBSCS\nBSED-MATH\nBTLED-HE\nCourse\n0\n10\n20\n30\n40\n50\n60\nFigure 2: Distribution of Respondents by Course\n\n3rd Year\n4th Year\n2nd Year\n1st Year\nYear\n0\n20\n40\n60\n80\nFigure 3: Distribution of Respondents by Year Level\n\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I don\nt understand the topic. \nI apply what I\nve learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorial\ns content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\n0\n1\n2\n3\n4\nFigure 4: Mean Likert Scores of Student Engagement Items\n\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I don\nt understand the topic. \nI apply what I\nve learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorial\ns content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\n3.5\n4.0\nFigure 5: Median Likert Scores of Survey Items\n\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I don\nt understand the topic. \nI apply what I\nve learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorial\ns content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n1.2\nFigure 6: Variance of Responses per Survey Item\n\nWatching online tutorials is enjoyable for me. I feel motivated to watch online tutorials about topics that interest me. I find online tutorials interesting and engaging. I feel satisfied after watching a helpful tutorial. I enjoy learning new skills or concepts through online tutorials. I wish the tutorials I watch would last longer when they are informative. I watch online tutorials regularly. I focus my attention while watching online tutorials. I take notes while watching tutorials to remember key points.I try to finish the entire tutorial video instead of stopping midway. I replay parts of a tutorial when I dont understand the topic. I apply what Ive learned from tutorials to real activities or assignments. I look for more tutorials on similar topics after watching one.I put effort into understanding the content of the tutorials I watch. I think deeply about how the tutorials content relates to what I already know. I try to summarize or explain the tutorial content in my own words. I use critical thinking to evaluate the accuracy of the tutorial information. I connect what I learn from tutorials to real-life applications. I review or revisit tutorials to reinforce my understanding.I seek additional resources to supplement what I learn from tutorials.\n2.0\n2.5\n3.0\n3.5\n4.0\n4.5\n5.0\nFigure 7: Distribution of Student Engagement Responses\n\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I don\nt understand the topic. \nI apply what I\nve learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorial\ns content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I dont understand the topic. \nI apply what Ive learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorials content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\nFigure 8: Correlation Between Student Engagement Items\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n\n3.253.503.754.004.254.504.755.00\nOverall_Engagement\n0\n20\n40\n60\n80\nCount\nFigure 9: Overall Student Engagement Score Distribution\n\nHigh\n95.7%\nModerate\n4.3%\n0.0%\nFigure 10: Overall Student Engagement Levels\n\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I don\nt understand the topic. \nI apply what I\nve learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorial\ns content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\n0\n10\n20\n30\n40\n50\n60\n70\n80\nFigure 11: Strongly Agree Responses per Item\n\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I don\nt understand the topic. \nI apply what I\nve learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorial\ns content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\n0\n10\n20\n30\n40\n50\n60\nFigure 12: Disagree Responses per Item\n\nAgreeDisagreeStrongly agree\nWatching online tutorials is enjoyable for me. \n0\n20\n40\n60\n80\n100\n120\n140\ncount\nFigure 13: Response Distribution: Watching online tutorials is enjoyable f...\n\nStrongly agreeAgreeDisagree\nI feel motivated to watch online tutorials about topics that interest me. \n0\n20\n40\n60\n80\n100\n120\n140\n160\ncount\nFigure 14: Response Distribution: I feel motivated to watch online tutoria...\n\nAgreeStrongly agreeDisagree\nI find online tutorials interesting and engaging. \n0\n20\n40\n60\n80\n100\n120\n140\n160\ncount\nFigure 15: Response Distribution: I find online tutorials interesting and ...\n\nStrongly agreeAgree\nI feel satisfied after watching a helpful tutorial. \n0\n20\n40\n60\n80\n100\n120\n140\n160\ncount\nFigure 16: Response Distribution: I feel satisfied after watching a helpfu...\n\nAgreeStrongly agreeDisagree\nI enjoy learning new skills or concepts through online tutorials. \n0\n20\n40\n60\n80\n100\n120\n140\n160\ncount\nFigure 17: Response Distribution: I enjoy learning new skills or concepts ...\n\nWatching online tutorials is enjoyable for me. \nI feel motivated to watch online tutorials about topics that interest me. \nI find online tutorials interesting and engaging. \nI feel satisfied after watching a helpful tutorial. \nI enjoy learning new skills or concepts through online tutorials. \nI wish the tutorials I watch would last longer when they are informative. \nI watch online tutorials regularly. \nI focus my attention while watching online tutorials. \nI take notes while watching tutorials to remember key points.\nI try to finish the entire tutorial video instead of stopping midway. \nI replay parts of a tutorial when I dont understand the topic. \nI apply what Ive learned from tutorials to real activities or assignments. \nI look for more tutorials on similar topics after watching one.\nI put effort into understanding the content of the tutorials I watch. \nI think deeply about how the tutorials content relates to what I already know. \nI try to summarize or explain the tutorial content in my own words. \nI use critical thinking to evaluate the accuracy of the tutorial information. \nI connect what I learn from tutorials to real-life applications. \nI review or revisit tutorials to reinforce my understanding.\nI seek additional resources to supplement what I learn from tutorials.\n1\n2\n3\n4\nFigure 18: Radar Chart of Mean Engagement Scores\n\nBEED\nBSCS\nBSED-MATH\nBSES\nBSHM\nBTLED-HE\nCourse\n0\n1\n2\n3\n4\nFigure 19: Mean Engagement Score by Course\n\n1st Year\n2nd Year\n3rd Year\n4th Year\nYear\n0\n1\n2\n3\n4\nFigure 20: Mean Engagement Score by Year Level"
  },
  {
    "filename": "1765888393290-Final-Defend-Manuscript-Libro.pdf",
    "originalName": "Final-Defend-Manuscript-Libro.pdf",
    "private": true
  },
  {
    "filename": "1765888598587-MOBILE-APPS-IN-AGRICULTURE-A-BOON-FOR-FARMERS (1).pdf",
    "originalName": "MOBILE-APPS-IN-AGRICULTURE-A-BOON-FOR-FARMERS (1).pdf",
    "private": true
  }
]